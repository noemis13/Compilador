\documentclass[12p, english,brazil,a4paper,utf8,onesidet]{article}
\usepackage{float}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[latin1]{inputenc}  
\usepackage{url}
\usepackage{indentfirst}
\usepackage[brazil]{babel} 
\usepackage{tabularx}
\usepackage{hhline}
\usepackage{xcolor}
\usepackage{nomencl}
\usepackage{indentfirst}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{etoolbox}
\usepackage{listings}
\usepackage{cleveref}
\usepackage{longtable}
     
% Suporte a figuras e subfiguras
\usepackage{graphics}
\usepackage{subfigure}
     
\sloppy

\title{Análise Léxica}

\author{Noemi Pereira Scherer\inst{1}}


\address{Universidade Tecnológica Federal do Paraná (UTFPR)
  \\
  Campo Mourão -- PR -- Brasil
  \email{\{noemischerer13\}@gmail.com}
}

\begin{document} 

\maketitle

\begin{abstract}
  This meta-article describes the procedures and results of developing a lexical and syntactic parser. The first one is responsible for verifying the input of character lines from a source code written T++, producing a sequence of lexical symbols. The second parses the source code in T ++ and returns an abstract tree. For the creation of these analyzers, a Python language library called PLY and YACC was used.
\end{abstract}
     
\begin{resumo} 
  Este meta-artigo descreve os procedimentos e resultados do desenvolvimento de um analisador léxico e sintática. O primeiro é responsável por verificar as entradas de linhas de caracteres de um código fonte escrito T++, produzindo uma sequência de símbolos léxicos. O segundo análise o código fonte em T++ e retorna uma árvore abstrata. Para a criação desses analisares, foi utilizado uma biblioteca da linguagem Python denominado PLY e YACC.
  
\end{resumo}


\section{Introdução}

%Compiladores
Um compilador é responsável pela tradução de um programa descrito em uma linguagem de alto nível para um programa equivalente em código de máquina. De forma geral, um compilador não produz diretamente um código de máquina e sim um programa em linguagem simbólica (\textit{assembly}) 
semanticamente equivalente ao código em linguagem de alto nível. Por meio de montadores, esse programa em linguagem simbólica é traduzida em uma linguagem de máquina \cite{compilador}.

Um compilador executa dois tipos de atividade, para desempenhar suas tarefas. A primeira é a análise do código fonte, no qual a estrutura e significado do programa de alto nível são reconhecidos. A segunda é a síntese do programa equivalente em linguagem simbólica \cite{compilador}.

Para exemplificar essas duas atividades, considere a Figura~\ref{exempleC} na qual descreve um código na linguagem C, que para um compilador é uma sequência de caracteres em um arquivo texto. O primeiro passo é reconhecer que agrupamentos de caracteres têm significado para o programa, por exemplo, saber que \texttt{int} é uma palavra-chave da linguagem e que \texttt{a} e \texttt{b} são variáveis neste programa. Posteriormente, o compilador deve reconhecer que a sequência \texttt{int a} corresponde a uma declaração de uma variável inteira cujo identificador recebeu o nome \texttt{a}. 

\begin{figure}[H]
\caption{Exemplo de código na linguagem C}
\label{exempleC}
\begin{lstlisting}[frame=single] 
int a, b, valor;
a = 10;
b = 20;
valor = a*(b+20)
\end{lstlisting}
\end{figure}
 


% Analise Lexica
A primeira análise é a léxica, que é um processo que analisa a entrada de linhas de caracteres (código fonte de um programa) e produz uma sequência de símbolos léxicos denominados \textit{tokens}, sendo facilmente manipulado por um \textit{parser} (leitor de saída) \cite{wikibook}.

O analisador léxico lê cada caractere do programa fonte e, traduz em uma saída os \textit{tokens}. Dessa forma, é possível reconhecer as palavras reservadas, constantes, identificadores e outras palavras que pertencem a linguagem de programação analisada. O analisador também pode executar outras tarefas como o tratamento de espaços, eliminação de comentários e contagem do número de linhas que o programa possui \cite{wikibook}.

O analisador léxico funciona de duas maneiras o primeiro e segundo estado da análise. O primeiro é responsável por ler a entrada de caracteres mudando o estado em que esses se encontram. Quando o analisador encontra um caractere o qual ele não considera como correto, ele volta à última análise que foi aceita. No segundo são repassados os caracteres encontrados para produzir um valor. O tipo do léxico é combinado com seu valor constituindo um símbolo, que pode ser denominado parser.

A implementação de um analisador léxico requer uma descrição do autômato que reconhece as sentenças da gramática ou expressão regular de cada \textit{token} que possui os seguintes procedimentos \cite{wikibook}:
\begin{itemize}
\item Estado inicial, que recebe como argumento a referência para o autômato e retorna o seu estado inicial;

\item Estado final, que recebe como argumentos a referência para o autômato e a referência para o estado corrente. O procedimento retorna verdadeiro se o estado especificado é elemento do conjunto de estados finais do autômato, ou falso caso contrário; e

\item Próximo estado, que recebe como argumento a referência para o autômato, para o estado corrente e para o símbolo sendo analisado. O procedimento consulta a tabela de transições e retorna o próximo estado do autômato, ou o valor nulo se não houver transição possível.
\end{itemize}

%Analise sintática
A segunda análise é a sintática (\textit{parser}) que determina a estrutura gramatical dos \textit{tokens} segundo uma determinada gramática formal. Ou seja, ela é um processo que determina se uma cadeia de símbolos léxicos pode ser gerada por uma gramática \cite{analiseSintatica}.

Nesta análise o compilador deve reconhecer que a sequência de \textit{tokens} corresponde a comandos relacionados à linguagem \cite{compilador}, como o código da Figura~\ref{exempleC}, o primeiro comando é a declaração de variáveis e os três outros são comandos de atribuições. 

A análise sintática transforma um texto na entrada em uma estrutura de dados, como uma árvore. Por meio dessa análise obtêm-se um grupo de \textit{tokens}, para que o analisador use um conjunto de regras para construir uma árvore sintática da estrutura \cite{wikibook}.

Essa análise aceita linguagens livre de contexto, e existem duas formas de determinar se a entrada de dados pode ser derivada de um símbolo inicial com as regras de uma gramática formal \cite{analiseSintatica}:

\textbf{Descendente (\textit{top-down})}: um analisador pode iniciar com o símbolo inicial e transformá-lo na entrada de dados. O analisador inicia dos maiores elementos e os quebra em partes menores, como exemplo, analisador sintático LL.

\textbf{Ascendente (\textit{bottom-up})}: um analisador pode iniciar com um entrada de dados e tentar reescrevê-la até o símbolo inicial. O analisador tenta localizar os elementos mais básicos, e então os maiores que contêm os elementos mais básicos, e assim por diante, como por exemplo, analisador sintático LR.


\subsection{Objetivo}
O objetivo desse trabalho é desenvolver um programa capaz de realizar a análise léxica e sintática de códigos fontes escrito na Linguagem T++, retornando uma arvore sintática abstrata da linguagem.

\section{A Linguagem T++} \label{sec:firstpage}
A linguagem T++ foi desenvolvida especialmente para ser utilizada na disciplina de compiladores. Ela é uma linguagem simples, contendo algumas palavras reservadas, símbolos e arranjos uni e bidimensionais. A Tabela \ref{linguagemt} mostra todas as palavras reservadas e símbolos que a linguagem T++ permite.


\begin{longtable}[c]{| c | c |}
 \caption{\textit{Tokens} permitidos pela Linguagem T++}\\
 
 \hline
 \multicolumn{2}{| c |}{Lista de tokens}\\
 \hline
 Palavras Reservadas & Símbolos\\
 \hline
 \endfirsthead
 
 \hline
 \multicolumn{2}{|c|}{Continuação lista de tokens}\\
 \hline
 Palavras Reservadas & Símbolos\\
 \hline
 \endhead
 
 \hline
 \endfoot
 
 \hline
 \multicolumn{2}{| c |}{Fim lista de tokens}\\
 \hline\hline
 \endlastfoot
 
se    & + soma\\
então & - subtração\\
senão & * multiplicação\\
fim	  & / divisão\\
repita& = igualdade\\
flutuante& , vírgula\\
retorna& := atribuição\\
até& $<$ menor\\
leia& $>$ maior\\
escreve& $<$= menor-igual\\
inteiro& $>$= maior-igual\\
notação científica &	$<>$= diferença\\
		& () abre e fecha parênteses\\
		& : dois pontos\\
		& [] abre e fecha colchetes\\
		& \{\} comentário\\
		& $|$ $|$ ou-lógico \\
		& \&\& e-lógico \\
		& ! negação \\
\end{longtable}
 
A construção do código dessa linguagem é inteiramente em Português. Os números podem ser inteiros, flutuantes (notação científica ou não), e as declarações de variáveis devem obrigatoriamente começar com letras precedente de várias letras e/ou números.
 
Apesar de T++ ser uma linguagem simples, ela permite a execução de algoritmos complexos, como de ordenação. A Figura~\ref{exemple} demonstra o algoritmo de busca soma vetor na linguagem t++.

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{figure}[H]
\caption{Exeplo do código BubbleSort na linguagem T++}
\label{exemple}
\begin{lstlisting}[frame=single] 
inteiro: T 
T:= 4
inteiro: V1[T]
inteiro somavet(inteiro: vet[], inteiro: tam)
	inteiro: result 
	result := 0
	inteiro: i 
	i := 0
	repita
		result := result + vet[i]
		i := i + 1
	até i = tam - 1
	retorna(result)	
fim
inteiro principal ()
	inteiro: x
	x := somavet(V1,T)
	retorna(0)
fim
\end{lstlisting}
\end{figure}

\section{Análise léxica}
\subsection{Expressões Regulares e Autômatos}

Uma expressão regular é responsável por identificar cadeia de caracteres de uma determinada linguagem, como palavras ou padrões. Elas são escritas numa linguagem formal que pode ser interpretada por um processador de expressão regular \cite{expRegular}.

Essa expressão pode ser associada com a aritmética, entretanto ao invés dela denotar um número (como 2+2), a expressão regular denota uma linguagem regular. Por exemplo: a0+, que resultará em \{"a0", "a00", "a000", ...\} \cite{expRegular}.

As expressões regulares são utilizadas para a especificação léxica de uma determinada linguagem. Para sua demonstração são utilizados autômatos finitos determinísticos.

Um autômato finito é um modelo computacional composto de uma fita de entrada dividida em células, nas quais contém os símbolos das cadeia. A principal parte do modelo é um controle finito, o qual indica em qual estado o autômato se encontra \cite{automatos}.

O modelo do autômato apresenta um estado inicial e um conjunto de estados finais. O estado inicial refere-se ao início de funcionamento do modelo, dependendo do símbolo presente na fita o próximo estado será escolhido, enquanto que os estados finais indicam o término do processo com sucesso, ou seja, se a cadeia presente na fita de entrada tiver sido completamente lida e o modelo não se encontrar em um estado final, considera-se a cadeia não aceita, ou caso contrário, como aceita \cite{automatos}.

% % %
Para cada \textit{token} permitido na Linguagem T++ é criado uma expressão regular, o qual tem como objetivo analisar uma cadeia de caracteres no código. As expressões regulares utilizadas nesse trabalho estão descritas na Tabela~\ref{expressaoRegulares}.

\begin{table}[ht]
\caption{Expressões regulares de cada token}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Tokens} & \textbf{Expressão regulares}\\ 
\hline

Soma & \textbackslash+ \\\hline
Subtração & - \\\hline
Multiplicação & \textbackslash* \\\hline
Divisão & \textbackslash/ \\\hline
Igual & \textbackslash = \\\hline
Vírgula & , \\\hline
Atribuição & \textbackslash:=+ \\\hline
Menor & \textbackslash< \\\hline
Maior & \textbackslash> \\\hline
Menor Igual & \textbackslash<= \\\hline
Maior igual & \textbackslash>= \\\hline
Abre parênteses & \textbackslash $($ \\\hline
Fecha parênteses & \textbackslash $)$ \\\hline
Abre colchetes & \textbackslash $[$ \\\hline
Fecha Colchetes & \textbackslash $]$ \\\hline
Dois pontos & : \\\hline
E lógico & \&\& \\\hline
OU lógico & $|$ $|$ \\\hline
Negação & ! \\\hline

ID & [a-zA-Zà-úÀ-Ú][\_0-9a-zà-úA-ZÀ-Ú]* \\\hline

Notação Científica & [0-9]+(\textbackslash .[0-9]+)*(e$|$ 
E)+(\textbackslash + $|$\textbackslash -)*[0-9]+(\textbackslash.[0-9])* \\\hline		

Flutuante & [0-9]+(\textbackslash.[0-9]+)(e( \textbackslash +$|$ \textbackslash-)?(\ d+))? \\\hline

Inteiro & [0-9]+ \\\hline

Comentário & \{ [ 
\textasciicircum \textbackslash \{ 
\textasciicircum \textbackslash \} ] \} \\\hline

Nova Linha & \textbackslash n+ \\\hline

\end{tabular}
\label{expressaoRegulares}
\end{table}

A ordem de execução de cada expressão regular é representada em forma de autômatos. Os autômatos mais simples são dos operadores (soma, subtração, divisão, multiplicação, abre e fecha parênteses e colchetes, atribuição, igualdade, vírgula, dois pontos, ou e e-lógico e negação) que são representados na Figura~\ref{fig:ExpressaoOperadores}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./palavrasReservadas}
\caption{Autômatos dos operadores.}
\label{fig:ExpressaoOperadores}
\end{figure}

Os autômatos da expressão regular do ID (identificador) estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoId1}), e outro detalhada (Figura~\ref{fig:ExpressaoId2}). O seu objetivo é identificar qualquer palavra ou letra presente no código, podendo ser letras maiúsculas, minúsculas, com ou sem assento. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./id1}
\caption{Autômato resumido da expressão regular do identificador (ID).}
\label{fig:ExpressaoId1}
\end{figure}
 

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{./id2}
\caption{Autômato completo da expressão regular do identificador (ID).}
\label{fig:ExpressaoId2}
\end{figure}

O autômato da expressão regular dos números inteiros recebe qualquer número de zero a nove uma ou várias vezes até chegar em seu estado final. Ele está representado na Figura~\ref{fig:ExpressaoInteiro}. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./inteiro1}
\caption{Autômato dos números inteiros.}
\label{fig:ExpressaoInteiro}
\end{figure}

O autômato da expressão regular dos números flutuantes está representado na Figura~\ref{fig:ExpressaoFlutuante}. Seu objetivo é identificar qualquer número que esteja separado por ponto no código, como 22.5 ou 0.22. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./flutuante2}
\caption{Autômato dos números flutuantes.}
\label{fig:ExpressaoFlutuante}
\end{figure}


O autômato da expressão regular dos números flutuantes em notação científica está representado na Figura~\ref{fig:ExpressaoNotacao}. Seu objetivo é identificar valor que possuem expoente no código, como 10E20 ou 10e-20. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./notacao}
\caption{Autômato dos números flutuantes em notação científica.}
\label{fig:ExpressaoNotacao}
\end{figure}


Os autômatos da expressão regular dos comentários estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoComent}) e outra detalhada (Figura~\ref{fig:ExpressaoComent2}). Os comentários no na linguagem T++ são representadas por qualquer palavra que esteja entre '\{\}', como exemplo: \{Esse é um comentário \}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./comentario1}
\caption{Autômato resumido do comentário.}
\label{fig:ExpressaoComent}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./comentario2}
\caption{Autômato completo do comentário.}
\label{fig:ExpressaoComent2}
\end{figure}


Por fim, o autômato da expressão regular da nova linha está representado representado na Figura~\ref{fig:ExpressaoLinha}. Seu objetivo é encontrar qualquer linha no código denotado por \textbackslash n.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./linha1}
\caption{Autômato da nova linha.}
\label{fig:ExpressaoLinha}
\end{figure}

\section{Análise sintática}
\subsection{Descrição da gramática BNF}
A \textit{Backus-Naur Form} (BNF) é uma forma matemática de descrever uma linguagem, de modo que defina a gramática da linguagem sem ambiguidade ou divergência \cite{bnf}.

Primeiramente é definido um símbolo inicial para a gramática (programa) e depois são criadas regras (produções) para substituição desse simbolo por outro \cite{bnf}.

A produção de uma regra segue a lógica de que o símbolo da esquerda do ':=' pode ser substituído por um simbolo a direita. As alternativas são separadas por | (ou).

As produções criadas e utilizadas para o desenvolvimento da análise sintática estão descritas na Tabela~\ref{bnf}.

\begin{longtable}[c]{| c  c |}
	\caption{Produções BNF.\label{bnf}}\\
	\hline
	\hline\hline
	\multicolumn{2}{| c |}{\textbf{Descrição BNF}}\\
	\hline
	\endfirsthead
	
	\hline
	\multicolumn{2}{|c|}{\textbf{Continuação descrição BNF}}\\
	\hline
	\endhead
	
	\hline
	\endfoot
	
	\hline
	\hline\hline
	\endlastfoot
	
	programa :=  & lista\_declaracoes\\\hline
	lista\_declaracoes :=  & lista\_declaracoes declaracao \\
	& $|$ declaracao \\
	& $|$ error      \\\hline
	declaracao:= & declaracao\_variaveis \\
	& $|$ inicializacao\_variaveis \\
	& $|$ declaracao\_funcao \\\hline
	declaracao\_variaveis := & tipo DOIS\_PONTOS lista\_variaveis \\\hline  declaracao\_variaveis := & tipo DOIS\_PONTOS error \\\hline
	inicializacao\_variaveis := & atribuicao\\\hline
	lista\_variaveis         := & lista\_variaveis VIRGULA var\\
	&$|$ var\\\hline
	var                   := & ID\\
	& $|$ ID indice\\\hline
	indice 				:= & indice ABRE\_COL expressao FECHA\_COL \\
	& $|$ ABRE\_COL expressao FECHA\_COL  \\\hline          
	indice 				:= & indice ABRE\_COL error FECHA\_COL\\
	& $|$ ABRE\_COL error FECHA\_COL\\
	& $|$ error FECHA\_COL\\
	& $|$ ABRE\_COL error\\
	& $|$ indice error FECHA\_COL\\
	& $|$ indice ABRE\_COL error \\\hline
	tipo :=				 & INTEIRO\\
	& $|$ FLUTUANTE \\\hline
	declaracao\_funcao := 	 & tipo cabecalho\\
	&  $|$ cabecalho\\\hline
	cabecalho := 			 & ID ABRE\_PAR lista\_parametros FECHA\_PAR corpo FIM \\\hline
	cabecalho := 			 & ID ABRE\_PAR lista\_parametros FECHA\_PAR corpo error \\\hline
	lista\_parametros :=    & lista\_parametros VIRGULA parametro\\
	&    $|$ parametro\\
	&    $|$ vazio \\\hline
	parametro := 			 & tipo DOIS\_PONTOS ID\\
	& $|$ parametro ABRE\_COL FECHA\_COL \\\hline
	corpo := 				 & corpo acao\\
	& $|$ vazio \\\hline
	acao := 				 & expressao\\
	& $|$ declaracao\_variaveis\\
	& $|$ se\\
	& $|$ repita\\
	& $|$ leia\\
	& $|$ escreva\\
	& $|$ retorna \\\hline 	     		
	se :=& SE expressao ENTAO corpo FIM\\
		 &              $|$ SE expressao ENTAO corpo SENAO corpo FIM\\\hline
	se\_error := & SE expressao error corpo FIM\\
		         &      $|$ error SENAO corpo FIM\\\hline
	repita :=& REPITA corpo ATE expressao\\\hline
	repita\_error :=& REPITA corpo error\\\hline
	atribuicao :=& var ATRIBUT expressao \\\hline
	leia :=& LEIA ABRE\_PAR var FECHA\_PAR\\\hline
	escreva :=&  ESCREVA ABRE\_PAR expressao FECHA\_PAR\\\hline
	retorna :=& RETORNA ABRE\_PAR expressao FECHA\_PAR\\\hline
	expressao :=& expressao\_logica\\
           & $|$ atribuicao\\\hline
	expressao\_logica :=& expressao\_simples\\
	&         $|$ expressao\_logica operador\_logico\\
	& expressao\_simples\\\hline
	expressao\_simples :=& expressao\_aditiva\\
     &            $|$ expressao\_simples \\
     & operador\_relacional expressao\_aditiva\\\hline
	expressao\_aditiva :=& expressao\_multiplicativa\\
	 &           $|$ expressao\_aditiva \\ & operador\_soma expressao\_multiplicativa\\\hline
		expressao\_multiplicativa :=& expressao\_unaria\\
		                           &	    $|$ expressao\_multiplicativa operador\_multiplicacao\\ & expressao\_unaria\\\hline
		expressao\_unaria :=& fator\\
		                     &        $|$ operador\_soma fator\\
					     &$|$ operador\_negacao fator\\\hline
		 operador\_relacional :=& MENOR\\
		                         &       $|$ MAIOR\\
		                         &       $|$ IGUAL\\
						&$|$ DIFERENCA\\
		                              &  $|$ MENOR\_IGUAL\\
		                              &  $|$ MAIOR\_IGUAL\\\hline
		  operador\_soma :=& SOMA\\
		                           & $|$ SUB\\\hline
		  operador\_negacao :=& NEGACAO\\\hline
		  operador\_logico :=& E\_LOGICO\\
		                           &   $|$ OU\_LOGICO\\\hline
		  operador\_multiplicacao :=& MULT\\
		                                  &    $|$ DIVISAO\\\hline
		                                      	                                                          
		  fator :=& ABRE\_COL expressao FECHA\_COL\\
		                 &   $|$ var\\
		                  &  $|$ chamada\_funcao\\
		                  &  $|$ numero\\\hline
		   numero :=& INTEIRO\\
		             &         $|$ FLUTUANTE\\
		   		  &  $|$ NOTACAO\_CIENTIFICA \\\hline
		   chamada\_funcao :=& ID ABRE\_PAR lista\_argumentos FECHA\_PAR \\\hline
		    lista\_argumentos :=& lista\_argumentos VIRGULA expressao\\
		                       &        $|$ expressao\\
		                       &        $|$ vazio\\\hline
	                               				                                	                   
\end{longtable}

\section{PLY - Python Lex Yacc}

O PLY é uma ferramenta da linguagem Python para construção de compiladores populares lex e yacc. O principal objetivo do PLY é permanecer fiel ao modo como as ferramentas lex/yacc tradicionais funcionam. Isso inclui fornecer validação extensiva de entradas, relatórios de erros e diagnósticos \cite{ply}. 

Como o PLY foi desenvolvido principalmente como uma ferramenta de instrução, é possível notar a exigência em sua especificação de regras de \textit{token} e gramática. Em parte, isso acontece para detectar erros comuns de programação feitos por usuários iniciantes.

O PLY consiste em dois módulos separados; lex.py e yacc.py, ambos encontrados em um pacote do Python chamado ply. O módulo lex.py é usado para dividir o texto de entrada em uma coleção de \textit{tokens} especificados por uma coleção de regras de expressão regular. O yacc.py é usado para reconhecer a sintaxe da linguagem que foi especificada na forma de uma gramática livre de contexto \cite{ply}. 

As duas ferramentas são destinadas a trabalhar juntas. O lex.py fornece uma interface externa na forma de uma função \texttt{token()} que retorna o próximo \textit{token} válido no fluxo de entrada. Já a yacc.py chama isso repetidamente para recuperar \textit{tokens} e invocar regras gramaticais. A saída de yacc.py é geralmente uma \textit{Abstract Syntax Tree} (AST) \cite{ply}. 


\subsection{PLY para análise léxica}
Para o desenvolvimento da análise léxica, foi utilizado apenas o módulo lex.py. Para isso, o primeiro passo foi instalar o ply no ambiente linux utilizando o seguinte comando:

\texttt{pipe3 install ply}

É importante ressaltar que a versão do python deve ser acima de 3, para aceitar caracteres com acento, pois na linguagem T++ existem palavras reservadas que obrigatoriamente possuem acentos, como então e senão.


Para utilizar a ferramenta no código fonte deve-se importar o ply por meio do seguinte comando:

\texttt{\textbf{import} ply.lex \textbf{as} lex}

No código fonte da análise léxica é necessário descrever quais são as palavras reservadas e os \textit{tokens} da linguagem, como demostra na Figura~\ref{fig:Codigo1}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{./cod1}
\caption{Palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo1}
\end{figure}

Para o reconhecimento das palavras reservadas e \textit{tokens}, são definidas as expressões regulares de cada uma no código fonte por meio de regras e funções (Figura~\ref{fig:Codigo2}). As expressões regulares já foram definidas na Tabela~\ref{expressaoRegulares}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{./cod2}
\caption{Expressões regulares das palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo2}
\end{figure}

\subsection{PLY para análise sintática}
Utiliza-se o \texttt{yacc.py} para analisar a sintaxe da linguagem. Ele utiliza uma técnica conhecida como analisador LR ou\textit{ shift-reduce parsing} \textit{LR}. Essa análise LR é uma técnica \textit{bottom up} que tenta reconhecer o lado direito de várias regras gramaticais. Sempre que um lado direito válido é encontrado na entrada, os símbolos de gramática são substituídos pelo símbolo de gramática no lado esquerdo \cite{ply}.

A implementação do analisador LR é responsável por deslocar símbolos da gramática para uma pilha, analisando a pilha e o próximo \textit{token} de entrada para padrões que correspondam a uma das regras gramaticais \cite{ply}. Como exemplo, considere a expressão \texttt{3 + 5 * (10 - 20)} e a gramática definida na Figura~\ref{fig:gramaticaExem}, a saída utilizando o analisador é demonstrada na Figura~\ref{fig:Exem}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth]{./gramaticaExemplo}
	\caption{Exemplo de regras gramaticais.}
	\label{fig:gramaticaExem}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{./exemplo}
	\caption{Exemplo do analisador LR.}
	\label{fig:Exem}
\end{figure}

De acordo com a Figura~\ref{fig:Exem}, uma máquina de estado subjacente e o \textit{token} de entrada atual determinam o passo seguinte. Se o próximo \textit{token} estiver descrito em uma regra gramatical válida, ele é transferido para a pilha. Se a parte superior da pilha contiver um lado direito válido de uma regra gramatical, ela é "reduzida" e os símbolos substituídos pelo símbolo à esquerda. Se o \textit{token} de entrada não puder ser deslocado e o topo da pilha não corresponder a nenhuma regra gramatical, ocorre um erro de sintaxe. Uma análise é considerada bem-sucedida quando o analisador atinge um estado em que a pilha de símbolos esteja vazia e não exista mais \textit{tokens} de entrada.

\subsubsection{A implementação utilizando YACC}
Para o desenvolvimento da análise sintática, foi utilizado o módulo \texttt{ply.yacc} e os \textit{tokens} obtidos da análise léxica. Para isso, foi necessário realizar duas importações no código:

\texttt{\textbf{import} ply.yacc \textbf{as} yacc}

\texttt{\textbf{from} lexer \textbf{import} Lexica}

Cada regra gramatical é definida por uma função Python, no qual cada uma contém a especificação gramatical livre de contexto apropriada. As instruções que compõem o corpo da função implementam as ações responsável por adicionar valores na árvore abstrata, como mostra parte do código na Figura~\ref{fig:syntax}. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{./syntax}
	\caption{Regras gramaticais representadas por meio de funções na linguagem Python.}
	\label{fig:syntax}
\end{figure}

Cada função aceita um único argumento p que é uma sequência contendo os valores de cada símbolo gramatical na regra correspondente. Os valores de \texttt{p[i]} são mapeados para símbolos de gramática, como o exemplo \textbf{\texttt{p[0] = Tree('declaracao'), [p[1]]}}, no qual é adicionada na árvore o valor p[1], que pode ser: \texttt{declaracao\_variaveis, inicializacao\_variaveis ou declaraca\_funcao}.

A primeira regra definida na especificação \textit{yacc} determina o símbolo de gramática inicial. Sempre que a regra inicial for reduzida pelo analisador e não houver mais entrada disponível, a análise será interrompida uma árvore abstrata contendo a gramática e valores será retornada.

A estrutura da árvore abstrata é criada em uma classe denominada \texttt{Tree} (Figura~\ref{fig:tree}). Os símbolos encontrados pelo analisador sintático são adicionados nessa árvore, que é imprime todos seus nós ao final da análise por meio de uma função chamda \texttt{prinTree} (Figura~\ref{fig:printtree}). 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{./tree}
	\caption{Estrutura da classe Tree em Python.}
	\label{fig:tree}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{./printTree}
	\caption{Função responsável por imprimir a árvore abstrata em python.}
	\label{fig:printtree}
\end{figure}


Para capturar os erros de sintaxe encontrados, existe um denominada \texttt{p\_error} que retorna a linha e a coluna do código onde ocorreu o erro, como demostra a Figura~\ref{fig:error}.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{./error}
	\caption{Função error em Python.}
	\label{fig:error}
\end{figure}

Para construir o analisador, é necessário chamar a função \texttt{yacc.yacc()}, no qual examina o módulo e tenta construir todas as tabelas de análise de LR para a gramática especificada.

\section{Resultados análise léxica}

Com o código fonte da análise léxica pronto, é possível executá-lo de forma que receba um arquivo contendo o código na linguagem T++, leia cada \textit{token} do mesmo, e retorne um arquivo de saída identificando cada \textit{token} encontrado, bem como sua linha e coluna.

Para executar o código pelo terminal utiliza-se o seguinte comando:

\texttt{python3 lexer.py nomeDoArquivo.tpp}

Considere a Figura~\ref{fig:fat} que demostra um código feito em T++ responsável por calcular o fatorial de um número. 

\begin{figure}[H]
\caption{Fatorial em T++.}
\label{fig:fat}
\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{lstlisting}[frame=single] 
inteiro: n
inteiro fatorial(inteiro: n)
    inteiro: fat
    se n > 0 então {não calcula se n > 0}
        fat := 1
        repita
            fat := fat * n
            n := n - 1
        até n = 0
        retorna(fat) {retorna o valor do fatorial de n}
    senão
        retorna(0)
    fim
fim
inteiro principal()
    leia(n)
    escreva(fatorial(n))
    retorna(0)
fim

\end{lstlisting}
\end{figure}

Ao executar a análise léxica o código fatorial (Figura~\ref{fig:fat}), tem-se a seguinte saída:

\begin{lstlisting}[frame=single] 
LexToken(INTEIRO,'inteiro',1,0)
LexToken(DOIS_PONTOS,':',1,7)
LexToken(ID,'n',1,9)
LexToken(NOVA_LINHA,'\n\n',1,10)
LexToken(INTEIRO,'inteiro',3,12)
LexToken(ID,'fatorial',3,20)
LexToken(ABRE_PAR,'(',3,28)
LexToken(INTEIRO,'inteiro',3,29)
LexToken(DOIS_PONTOS,':',3,36)
LexToken(ID,'n',3,38)
LexToken(FECHA_PAR,')',3,39)
LexToken(NOVA_LINHA,'\n',3,40)
LexToken(INTEIRO,'inteiro',4,45)
LexToken(DOIS_PONTOS,':',4,52)
LexToken(ID,'fat',4,54)
LexToken(NOVA_LINHA,'\n',4,57)
LexToken(SE,'se',5,62)
LexToken(ID,'n',5,65)
LexToken(MAIOR,'>',5,67)
LexToken(INTEIRO,'0',5,69)
LexToken(ENTAO,'então',5,71)
LexToken(COMENTARIO,'{não calcula se n > 0}',5,77)
LexToken(NOVA_LINHA,'\n',5,99)
LexToken(ID,'fat',6,108)
LexToken(ATRIBUICAO,':=',6,112)
LexToken(INTEIRO,'1',6,115)
LexToken(NOVA_LINHA,'\n',6,116)
LexToken(REPITA,'repita',7,125)
LexToken(NOVA_LINHA,'\n',7,131)
LexToken(ID,'fat',8,144)
LexToken(ATRIBUICAO,':=',8,148)
LexToken(ID,'fat',8,151)
LexToken(MULT,'*',8,155)
LexToken(ID,'n',8,157)
LexToken(NOVA_LINHA,'\n',8,158)
LexToken(ID,'n',9,171)
LexToken(ATRIBUICAO,':=',9,173)
LexToken(ID,'n',9,176)
LexToken(SUB,'-',9,178)
LexToken(INTEIRO,'1',9,180)
LexToken(NOVA_LINHA,'\n',9,181)
LexToken(ATE,'até',10,190)
LexToken(ID,'n',10,194)
LexToken(IGUAL,'=',10,196)
LexToken(INTEIRO,'0',10,198)
LexToken(NOVA_LINHA,'\n',10,199)
LexToken(RETORNA,'retorna',11,208)
LexToken(ABRE_PAR,'(',11,215)
LexToken(ID,'fat',11,216)
LexToken(FECHA_PAR,')',11,219)
LexToken(COMENTARIO,'{retorna ...}',11,221)
LexToken(NOVA_LINHA,'\n',11,255)
LexToken(SENAO,'senão',12,260)
LexToken(NOVA_LINHA,'\n',12,265)
LexToken(RETORNA,'retorna',13,274)
LexToken(ABRE_PAR,'(',13,281)
LexToken(INTEIRO,'0',13,282)
LexToken(FECHA_PAR,')',13,283)
LexToken(NOVA_LINHA,'\n',13,284)
LexToken(FIM,'fim',14,289)
\end{lstlisting}

É possível notar que o código da análise léxica avaliou cada palavra do código em T++, o classificou e retornou seu valor em um arquivo de saída. Isso é exatamente o objetivo da análise léxica, retornar todos os \textit{tokens} que um determinado código possui.


\section{Resultados análise sintática}
O código da análise sintática recebe um arquivo contendo o código na linguagem T++. Ele chama a análise léxica para obter os \textit{tokens} e analisar se esses correspondem a gramática descrita.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{./codigo}
	\caption{Código em T++.}
	\label{fig:codigo}
\end{figure}

Considere o código fatorial da Figura~\ref{fig:codigo}, a saída obtida quando executado a análise sintática desse código é uma árvore abstrata:

\begin{lstlisting}[frame=single] 
  programa 
   lista_declaracoes 
    lista_declaracoes 
     declaracao 
      declaracao_funcao 
       tipo inteiro
       cabecalho func
        lista_parametros 
        corpo 
         corpo 
         acao 
          retorna 
           expressao 
            expressao_logica 
             expressao_simples 
              expressao_aditiva 
               expressao_multiplicativa 
                expressao_unaria 
                 fator 
                  numero 0
    declaracao 
     declaracao_funcao 
      tipo inteiro
      cabecalho principal
       lista_parametros 
       corpo 
        corpo 
         corpo 
          corpo 
          acao 
           declaracao_variaveis :
            tipo inteiro
            lista_variaveis 
             lista_variaveis 
              var i
             var b
         acao 
          expressao 
           atribuicao 
            var i
            expressao 
             expressao_logica 
              expressao_simples 
               expressao_aditiva 
                expressao_multiplicativa 
                 expressao_unaria 
                  fator 
                   numero 1
        acao 
         retorna 
          expressao 
           expressao_logica 
            expressao_simples 
             expressao_aditiva 
              expressao_multiplicativa 
               expressao_unaria 
                fator 
                 numero 0

\end{lstlisting}


\bibliographystyle{sbc}
\bibliography{sbc-template}
\nocite{expRegular}
\end{document}
