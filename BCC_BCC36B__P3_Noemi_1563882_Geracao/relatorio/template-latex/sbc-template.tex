\documentclass[12p, english,brazil,a4paper,utf8,onesidet]{article}
\usepackage{float}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[latin1]{inputenc}  
\usepackage{url}
\usepackage{indentfirst}
\usepackage[brazil]{babel} 
\usepackage{tabularx}
\usepackage{hhline}
\usepackage{xcolor}
\usepackage{nomencl}
\usepackage{indentfirst}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{etoolbox}
\usepackage{listings}
\usepackage{cleveref}
\usepackage{longtable}
     
% Suporte a figuras e subfiguras
\usepackage{graphics}
\usepackage{subfigure}
     
\sloppy

\title{Compilador: análise léxica, sintática, semântica e geração de código da linguagem T++}

\author{Noemi Pereira Scherer\inst{1}}


\address{Universidade Tecnológica Federal do Paraná (UTFPR)
  \\
  Campo Mourão -- PR -- Brasil
  \email{\{noemischerer13\}@gmail.com}
}

\begin{document} 

\maketitle

\begin{abstract}
 This meta-article describes the procedures and results of the development of a lexical, syntactic, semantic analyzer and and intermediate code generation. The first one is responsible for verifying the input of character lines from a source code written T++, producing a sequence of lexical symbols. The second analyzes the source code in T++ and returns an abstract tree. The third runs through this tree in order to find and report errors in the language. And the last one uses Python LLVM to generate and run parsed code. For the creation of these analyzers, a Python language library called PLY and YACC was used.
 
\end{abstract}
     
\begin{resumo} 
  Este meta-artigo descreve os procedimentos e resultados do desenvolvimento de um analisador léxico, sintático, semântico e geração de código intermediário. O primeiro é responsável por verificar as entradas de linhas de caracteres de um código fonte escrito T++, produzindo uma sequência de símbolos léxicos. O segundo analisa o código fonte em T++ e retorna uma árvore abstrata. O terceiro percorre essa árvore com o objetivo de encontrar e informar erros na linguagem. Por fim, o quarto utiliza o LLVM do Python para gerar e executar o código analisado. Para a criação desses analisares, foi utilizado uma biblioteca da linguagem Python denominado PLY e YACC.
  
\end{resumo}


\section{Introdução}

%Compiladores
Um compilador é responsável pela tradução de um programa descrito em uma linguagem de alto nível para um programa equivalente em código de máquina. De forma geral, um compilador não produz diretamente um código de máquina e sim um programa em linguagem simbólica (\textit{assembly}) 
semanticamente equivalente ao código em linguagem de alto nível. Por meio de montadores, esse programa em linguagem simbólica é traduzida em uma linguagem de máquina \cite{compilador}.

Um compilador executa dois tipos de atividade, para desempenhar suas tarefas. A primeira é a análise do código fonte, no qual a estrutura e significado do programa de alto nível são reconhecidos. A segunda é a síntese do programa equivalente em linguagem simbólica \cite{compilador}.

Para exemplificar essas duas atividades, considere a Figura~\ref{exempleC} na qual descreve um código na linguagem C, que para um compilador é uma sequência de caracteres em um arquivo texto. O primeiro passo é reconhecer que agrupamentos de caracteres têm significado para o programa, por exemplo, saber que \texttt{int} é uma palavra-chave da linguagem e que \texttt{a} e \texttt{b} são variáveis neste programa. Posteriormente, o compilador deve reconhecer que a sequência \texttt{int a} corresponde a uma declaração de uma variável inteira cujo identificador recebeu o nome \texttt{a}. 

\begin{figure}[H]
\caption{Exemplo de código na linguagem C}
\label{exempleC}
\begin{lstlisting}[frame=single] 
int a, b, valor;
a = 10;
b = 20;
valor = a*(b+20)
\end{lstlisting}
\end{figure}
 


% Analise Lexica
A primeira análise é a léxica, que é um processo que analisa a entrada de linhas de caracteres (código fonte de um programa) e produz uma sequência de símbolos léxicos denominados \textit{tokens}, sendo facilmente manipulado por um \textit{parser} (leitor de saída) \cite{wikibook}.

O analisador léxico lê cada caractere do programa fonte e, traduz em uma saída os \textit{tokens}. Dessa forma, é possível reconhecer as palavras reservadas, constantes, identificadores e outras palavras que pertencem a linguagem de programação analisada. O analisador também pode executar outras tarefas como o tratamento de espaços, eliminação de comentários e contagem do número de linhas que o programa possui \cite{wikibook}.

O analisador léxico funciona de duas maneiras o primeiro e segundo estado da análise. O primeiro é responsável por ler a entrada de caracteres mudando o estado em que esses se encontram. Quando o analisador encontra um caractere o qual ele não considera como correto, ele volta à última análise que foi aceita. No segundo são repassados os caracteres encontrados para produzir um valor. O tipo do léxico é combinado com seu valor constituindo um símbolo, que pode ser denominado parser.

A implementação de um analisador léxico requer uma descrição do autômato que reconhece as sentenças da gramática ou expressão regular de cada \textit{token} que possui os seguintes procedimentos \cite{wikibook}:
\begin{itemize}
\item Estado inicial, que recebe como argumento a referência para o autômato e retorna o seu estado inicial;

\item Estado final, que recebe como argumentos a referência para o autômato e a referência para o estado corrente. O procedimento retorna verdadeiro se o estado especificado é elemento do conjunto de estados finais do autômato, ou falso caso contrário; e

\item Próximo estado, que recebe como argumento a referência para o autômato, para o estado corrente e para o símbolo sendo analisado. O procedimento consulta a tabela de transições e retorna o próximo estado do autômato, ou o valor nulo se não houver transição possível.
\end{itemize}

%Analise sintática
A segunda análise é a sintática (\textit{parser}) que determina a estrutura gramatical dos \textit{tokens} segundo uma determinada gramática formal. Ou seja, ela é um processo que determina se uma cadeia de símbolos léxicos pode ser gerada por uma gramática \cite{analiseSintatica}.

Nesta análise o compilador deve reconhecer que a sequência de \textit{tokens} corresponde a comandos relacionados à linguagem \cite{compilador}, como o código da Figura~\ref{exempleC}, o primeiro comando é a declaração de variáveis e os três outros são comandos de atribuições. 

A análise sintática transforma um texto na entrada em uma estrutura de dados, como uma árvore. Por meio dessa análise obtêm-se um grupo de \textit{tokens}, para que o analisador use um conjunto de regras para construir uma árvore sintática da estrutura \cite{wikibook}.

Essa análise aceita linguagens livre de contexto, e existem duas formas de determinar se a entrada de dados pode ser derivada de um símbolo inicial com as regras de uma gramática formal \cite{analiseSintatica}:

\textbf{Descendente (\textit{top-down})}: um analisador pode iniciar com o símbolo inicial e transformá-lo na entrada de dados. O analisador inicia dos maiores elementos e os quebra em partes menores, como exemplo, analisador sintático LL.

\textbf{Ascendente (\textit{bottom-up})}: um analisador pode iniciar com um entrada de dados e tentar reescrevê-la até o símbolo inicial. O analisador tenta localizar os elementos mais básicos, e então os maiores que contêm os elementos mais básicos, e assim por diante, como por exemplo, analisador sintático LR.

%análise semântica
A terceira análise é a semântica, responsável por verificar os erros de semântica no código fonte e coletar informações necessárias para a próxima fase da compilação, a geração de código. O objetivo dessa análise é trabalhar no nível de inter-relacionamento entre partes distintas do programa \cite{wikiSeman}.

Considere o seguinte exemplo de código em C (Figura~\ref{exempleC}):
\begin{figure}[H]
\caption{Exemplo de código em C}
\label{exempleSem}
\begin{lstlisting}[frame=single] 
int f1(int a, float b) {
  return a%b;
}
\end{lstlisting}
\end{figure}

A tentativa de compilar esse código irá gerar um erro detectado pelo analisador semântico, mais especificamente pelas regras de verificação de tipos, indicando que o operador módulo \% não pode ter um operador real \cite{semantica}. 

Na análise semântica, são utilizadas verificações de tipos para certificar se um determinado operando recebe outro do mesmo tipo. Como exemplo, bem comum nas linguagens de programação, a análise semântica retorna um erro quando uma variável de tipo numérica (real ou inteira) recebe um valor do tipo texto (\textit{string}) \cite{wikiSeman}. Também são verificados erros no código, os exemplos de erros semânticos mais comum são:


\begin{itemize}
\item Uma variável não declarada;
\item Uma multiplicação entre tipos de dados diferentes;
\item Atribuição de um literal para outro tipo, como um inteiro em uma \textit{string} ou vice-versa.
\end{itemize}

Para guardar as informações sobre os nomes declarados no programa, a semântica utiliza uma tabela de símbolos (TS). A TS é referenciada toda vez que um nome é encontrado no programa fonte. Alterações são feitas na TS sempre que um novo nome ou nova informação sobre um já existente é obtida. A TS deve ser criada de forma a permitir inserções e consultas da forma mais eficiente possível, além de permitir o seu crescimento dinâmico. Cada entrada na tabela é a declaração de um nome, que pode ser implementada como um registro (\textit{struct}) contendo campos (nome, tipo, classe, tamanho, escopo, etc.) que a qualificam \cite{wikiSeman}.

%geração de código
Por fim, gera-se um código intermediário para obter o resultado final. A análise léxica e sintática apresentam técnicas com forte embasamento teórico e conceitual para permitir reconhecer os símbolos e as expressões tipicamente utilizadas em linguagens de programação de alto nível. No entanto, a operação de um compilador requer mais que o simples reconhecimento da validade de um programa; é preciso gerar o código equivalente que será efetivamente executado pelos processadores \cite{Geracao}. 


A geração de código não associa-se diretamente para a linguagem \textit{assembly} do processador-alvo. O analisador sintático gera um código para uma máquina abstrata, com uma linguagem próxima a \textit{assembly} porém, independente de processadores específicos. Em uma segunda etapa de geração de código, esse código intermediário é traduzido para a linguagem \textit{assembly} desejada. Dessa forma, grande parte do compilador é reaproveitada para trabalhar com diferentes tipos de processadores \cite{Geracao}.

A linguagem utilizada para a geração de um código em formato intermediário entre a linguagem de alto nível e a linguagem \textit{assembly} representa, de forma independente do processador para o qual o programa será gerado, todas as expressões do programa original. Existem duas formas usuais para esse tipo de representação, a notação pós-fixa e o código de três endereços \cite{Geracao}.

O gerador de código independente do LLVM é uma estrutura que fornece um conjunto de componentes reutilizáveis para traduzir a representação interna do LLVM para o código de máquina para um destino especificado - em formato de montagem ou em formato de código de máquina binário. O gerador de código independente de destino do LLVM consiste em seis componentes principais \cite{llvm}:

\begin{itemize}
\item interfaces de descrição de alvo abstratas que capturam propriedades importantes sobre vários aspectos da máquina, independentemente de como elas serão usadas;
\item  classes usadas para representar o código que está sendo gerado para um destino. Essas classes devem ser abstratas o suficiente para representar o código da máquina para qualquer máquina de destino; 
\item Classes e algoritmos usados para representar código no nível do objeto, o MC Layer. Essas classes representam construções de nível de montagem, como rótulos, seções e instruções;
\item  Algoritmos independentes de alvos utilizados para implementar várias fases de geração de código nativo (alocação de registros, agendamento, representação de quadros de pilha, etc).
\item Implementações das interfaces de descrição de destino abstratas para destinos específicos. Essas descrições de máquina fazem uso dos componentes fornecidos pelo LLVM e podem, opcionalmente, fornecer passagens personalizadas específicas do destino para construir geradores de códigos completos para um destino específico.
\item  Os componentes JIT independentes de destino. O LLVM JIT é completamente independente de destino. 
\end{itemize}


\subsection{Objetivo}
O objetivo desse trabalho é desenvolver um compilador capaz de realizar a análise léxica, sintática, semântica e a geração de códigos fontes escrito na Linguagem T++, retornando uma arvore sintática abstrata, erros presentes na linguagem e os resultados do código.


\section{A Linguagem T++} \label{sec:firstpage}
A linguagem T++ foi desenvolvida especialmente para ser utilizada na disciplina de compiladores. Ela é uma linguagem simples, contendo algumas palavras reservadas, símbolos e arranjos uni e bidimensionais. A Tabela \ref{linguagemt} mostra todas as palavras reservadas e símbolos que a linguagem T++ permite.

\begin{center}
\label{linguagemt}
\begin{longtable}[c]{| c | c |}
 \caption{\textit{Tokens} permitidos pela Linguagem T++}\\
 
 \hline
 \multicolumn{2}{| c |}{Lista de tokens}\\
 \hline
 Palavras Reservadas & Símbolos\\
 \hline
 \endfirsthead
 
 \hline
 \multicolumn{2}{|c|}{Continuação lista de tokens}\\
 \hline
 Palavras Reservadas & Símbolos\\
 \hline
 \endhead
 
 \hline
 \endfoot
 
 \hline
 \multicolumn{2}{| c |}{Fim lista de tokens}\\
 \hline\hline
 \endlastfoot
 
se    & + soma\\
então & - subtração\\
senão & * multiplicação\\
fim	  & / divisão\\
repita& = igualdade\\
flutuante& , vírgula\\
retorna& := atribuição\\
até& $<$ menor\\
leia& $>$ maior\\
escreve& $<$= menor-igual\\
inteiro& $>$= maior-igual\\
notação científica &	$<>$= diferença\\
		& () abre e fecha parênteses\\
		& : dois pontos\\
		& [] abre e fecha colchetes\\
		& \{\} comentário\\
		& $|$ $|$ ou-lógico \\
		& \&\& e-lógico \\
		& ! negação \\
\end{longtable}
\end{center}
A construção do código dessa linguagem é inteiramente em Português. Os números podem ser inteiros, flutuantes (notação científica ou não), e as declarações de variáveis devem obrigatoriamente começar com letras precedente de várias letras e/ou números.
 
Apesar de T++ ser uma linguagem simples, ela permite a execução de algoritmos complexos, como de ordenação. A Figura~\ref{exemple} demonstra o algoritmo de busca soma vetor na linguagem t++.

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{figure}[H]
\caption{Exemplo do código BubbleSort na linguagem T++}
\label{exemple}
\begin{lstlisting}[frame=single] 
inteiro: T 
T:= 4
inteiro: V1[T]
inteiro somavet(inteiro: vet[], inteiro: tam)
	inteiro: result 
	result := 0
	inteiro: i 
	i := 0
	repita
		result := result + vet[i]
		i := i + 1
	até i = tam - 1
	retorna(result)	
fim
inteiro principal ()
	inteiro: x
	x := somavet(V1,T)
	retorna(0)
fim
\end{lstlisting}
\end{figure}

\section{Análise léxica}
\subsection{Expressões Regulares e Autômatos}

Uma expressão regular é responsável por identificar cadeia de caracteres de uma determinada linguagem, como palavras ou padrões. Elas são escritas numa linguagem formal que pode ser interpretada por um processador de expressão regular \cite{expRegular}.

Essa expressão pode ser associada com a aritmética, entretanto ao invés dela denotar um número (como 2+2), a expressão regular denota uma linguagem regular. Por exemplo: a0+, que resultará em \{"a0", "a00", "a000", ...\} \cite{expRegular}.

As expressões regulares são utilizadas para a especificação léxica de uma determinada linguagem. Para sua demonstração são utilizados autômatos finitos determinísticos.

Um autômato finito é um modelo computacional composto de uma fita de entrada dividida em células, nas quais contém os símbolos das cadeia. A principal parte do modelo é um controle finito, o qual indica em qual estado o autômato se encontra \cite{automatos}.

O modelo do autômato apresenta um estado inicial e um conjunto de estados finais. O estado inicial refere-se ao início de funcionamento do modelo, dependendo do símbolo presente na fita o próximo estado será escolhido, enquanto que os estados finais indicam o término do processo com sucesso, ou seja, se a cadeia presente na fita de entrada tiver sido completamente lida e o modelo não se encontrar em um estado final, considera-se a cadeia não aceita, ou caso contrário, como aceita \cite{automatos}.

% % %
Para cada \textit{token} permitido na Linguagem T++ é criado uma expressão regular, o qual tem como objetivo analisar uma cadeia de caracteres no código. As expressões regulares utilizadas nesse trabalho estão descritas na Tabela~\ref{expressaoRegulares}.

\begin{table}[h]
\caption{Expressões regulares de cada token}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Tokens} & \textbf{Expressão regulares}\\ 
\hline

Soma & \textbackslash+ \\\hline
Subtração & - \\\hline
Multiplicação & \textbackslash* \\\hline
Divisão & \textbackslash/ \\\hline
Igual & \textbackslash = \\\hline
Vírgula & , \\\hline
Atribuição & \textbackslash:=+ \\\hline
Menor & \textbackslash< \\\hline
Maior & \textbackslash> \\\hline
Menor Igual & \textbackslash<= \\\hline
Maior igual & \textbackslash>= \\\hline
Abre parênteses & \textbackslash $($ \\\hline
Fecha parênteses & \textbackslash $)$ \\\hline
Abre colchetes & \textbackslash $[$ \\\hline
Fecha Colchetes & \textbackslash $]$ \\\hline
Dois pontos & : \\\hline
E lógico & \&\& \\\hline
OU lógico & $|$ $|$ \\\hline
Negação & ! \\\hline

ID & [a-zA-Zà-úÀ-Ú][\_0-9a-zà-úA-ZÀ-Ú]* \\\hline

Notação Científica & [0-9]+(\textbackslash .[0-9]+)*(e$|$ 
E)+(\textbackslash + $|$\textbackslash -)*[0-9]+(\textbackslash.[0-9])* \\\hline		

Flutuante & [0-9]+(\textbackslash.[0-9]+)(e( \textbackslash +$|$ \textbackslash-)?(\ d+))? \\\hline

Inteiro & [0-9]+ \\\hline

Comentário & \{ [ 
\textasciicircum \textbackslash \{ 
\textasciicircum \textbackslash \} ] \} \\\hline

Nova Linha & \textbackslash n+ \\\hline

\end{tabular}
\label{expressaoRegulares}
\end{table}

A ordem de execução de cada expressão regular é representada em forma de autômatos. Os autômatos mais simples são dos operadores (soma, subtração, divisão, multiplicação, abre e fecha parênteses e colchetes, atribuição, igualdade, vírgula, dois pontos, ou e e-lógico e negação) que são representados na Figura~\ref{fig:ExpressaoOperadores}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./palavrasReservadas}
\caption{Autômatos dos operadores.}
\label{fig:ExpressaoOperadores}
\end{figure}

Os autômatos da expressão regular do ID (identificador) estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoId1}), e outro detalhada (Figura~\ref{fig:ExpressaoId2}). O seu objetivo é identificar qualquer palavra ou letra presente no código, podendo ser letras maiúsculas, minúsculas, com ou sem assento. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./id1}
\caption{Autômato resumido da expressão regular do identificador (ID).}
\label{fig:ExpressaoId1}
\end{figure}
 

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{./id2}
\caption{Autômato completo da expressão regular do identificador (ID).}
\label{fig:ExpressaoId2}
\end{figure}

O autômato da expressão regular dos números inteiros recebe qualquer número de zero a nove uma ou várias vezes até chegar em seu estado final. Ele está representado na Figura~\ref{fig:ExpressaoInteiro}. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./inteiro1}
\caption{Autômato dos números inteiros.}
\label{fig:ExpressaoInteiro}
\end{figure}

O autômato da expressão regular dos números flutuantes está representado na Figura~\ref{fig:ExpressaoFlutuante}. Seu objetivo é identificar qualquer número que esteja separado por ponto no código, como 22.5 ou 0.22. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./flutuante2}
\caption{Autômato dos números flutuantes.}
\label{fig:ExpressaoFlutuante}
\end{figure}


O autômato da expressão regular dos números flutuantes em notação científica está representado na Figura~\ref{fig:ExpressaoNotacao}. Seu objetivo é identificar valor que possuem expoente no código, como 10E20 ou 10e-20. 

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./notacao}
\caption{Autômato dos números flutuantes em notação científica.}
\label{fig:ExpressaoNotacao}
\end{figure}


Os autômatos da expressão regular dos comentários estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoComent}) e outra detalhada (Figura~\ref{fig:ExpressaoComent2}). Os comentários no na linguagem T++ são representadas por qualquer palavra que esteja entre '\{\}', como exemplo: \{Esse é um comentário \}.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./comentario1}
\caption{Autômato resumido do comentário.}
\label{fig:ExpressaoComent}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./comentario2}
\caption{Autômato completo do comentário.}
\label{fig:ExpressaoComent2}
\end{figure}


Por fim, o autômato da expressão regular da nova linha está representado representado na Figura~\ref{fig:ExpressaoLinha}. Seu objetivo é encontrar qualquer linha no código denotado por \textbackslash n.

\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{./linha1}
\caption{Autômato da nova linha.}
\label{fig:ExpressaoLinha}
\end{figure}

\section{Análise sintática}
\subsection{Descrição da gramática BNF}
A \textit{Backus-Naur Form} (BNF) é uma forma matemática de descrever uma linguagem, de modo que defina a gramática da linguagem sem ambiguidade ou divergência \cite{bnf}.

Primeiramente é definido um símbolo inicial para a gramática (programa) e depois são criadas regras (produções) para substituição desse simbolo por outro \cite{bnf}.

A produção de uma regra segue a lógica de que o símbolo da esquerda do ':=' pode ser substituído por um simbolo a direita. As alternativas são separadas por | (ou).

As produções criadas e utilizadas para o desenvolvimento da análise sintática estão descritas na Tabela~\ref{bnf}.

\begin{longtable}[c]{| c  c |}
	\caption{Produções BNF.\label{bnf}}\\
	\hline
	\hline\hline
	\multicolumn{2}{| c |}{\textbf{Descrição BNF}}\\
	\hline
	\endfirsthead
	
	\hline
	\multicolumn{2}{|c|}{\textbf{Continuação descrição BNF}}\\
	\hline
	\endhead
	
	\hline
	\endfoot
	
	\hline
	\hline
	\endlastfoot
	
	programa :=  & lista\_declaracoes\\\hline
	lista\_declaracoes :=  & lista\_declaracoes declaracao \\
	& $|$ declaracao \\
	& $|$ error      \\\hline
	declaracao:= & declaracao\_variaveis \\
	& $|$ inicializacao\_variaveis \\
	& $|$ declaracao\_funcao \\\hline
	declaracao\_variaveis := & tipo DOIS\_PONTOS lista\_variaveis \\\hline  declaracao\_variaveis := & tipo DOIS\_PONTOS error \\\hline
	inicializacao\_variaveis := & atribuicao\\\hline
	lista\_variaveis         := & lista\_variaveis VIRGULA var\\
	&$|$ var\\\hline
	var                   := & ID\\
	& $|$ ID indice\\\hline
	indice 				:= & indice ABRE\_COL expressao FECHA\_COL \\
	& $|$ ABRE\_COL expressao FECHA\_COL  \\\hline          
	indice 				:= & indice ABRE\_COL error FECHA\_COL\\
	& $|$ ABRE\_COL error FECHA\_COL\\
	& $|$ error FECHA\_COL\\
	& $|$ ABRE\_COL error\\
	& $|$ indice error FECHA\_COL\\
	& $|$ indice ABRE\_COL error \\\hline
	tipo :=				 & INTEIRO\\
	& $|$ FLUTUANTE \\\hline
	declaracao\_funcao := 	 & tipo cabecalho\\
	&  $|$ cabecalho\\\hline
	cabecalho := 			 & ID ABRE\_PAR lista\_parametros FECHA\_PAR corpo FIM \\\hline
	cabecalho := 			 & ID ABRE\_PAR lista\_parametros FECHA\_PAR corpo error \\\hline
	lista\_parametros :=    & lista\_parametros VIRGULA parametro\\
	&    $|$ parametro\\
	&    $|$ vazio \\\hline
	parametro := 			 & tipo DOIS\_PONTOS ID\\
	& $|$ parametro ABRE\_COL FECHA\_COL \\\hline
	corpo := 				 & corpo acao\\
	& $|$ vazio \\\hline
	acao := 				 & expressao\\
	& $|$ declaracao\_variaveis\\
	& $|$ se\\
	& $|$ repita\\
	& $|$ leia\\
	& $|$ escreva\\
	& $|$ retorna \\\hline 	     		
	se :=& SE expressao ENTAO corpo FIM\\
		 &              $|$ SE expressao ENTAO corpo SENAO corpo FIM\\\hline
	se\_error := & SE expressao error corpo FIM\\
		         &      $|$ error SENAO corpo FIM\\\hline
	repita :=& REPITA corpo ATE expressao\\\hline
	repita\_error :=& REPITA corpo error\\\hline
	atribuicao :=& var ATRIBUT expressao \\\hline
	leia :=& LEIA ABRE\_PAR var FECHA\_PAR\\\hline
	escreva :=&  ESCREVA ABRE\_PAR expressao FECHA\_PAR\\\hline
	retorna :=& RETORNA ABRE\_PAR expressao FECHA\_PAR\\\hline
	expressao :=& expressao\_logica\\
           & $|$ atribuicao\\\hline
	expressao\_logica :=& expressao\_simples\\
	&         $|$ expressao\_logica operador\_logico\\
	& expressao\_simples\\\hline
	expressao\_simples :=& expressao\_aditiva\\
     &            $|$ expressao\_simples \\
     & operador\_relacional expressao\_aditiva\\\hline
	expressao\_aditiva :=& expressao\_multiplicativa\\
	 &           $|$ expressao\_aditiva \\ & operador\_soma expressao\_multiplicativa\\\hline
		expressao\_multiplicativa :=& expressao\_unaria\\
		                           &	    $|$ expressao\_multiplicativa operador\_multiplicacao\\ & expressao\_unaria\\\hline
		expressao\_unaria :=& fator\\
		                     &        $|$ operador\_soma fator\\
					     &$|$ operador\_negacao fator\\\hline
		 operador\_relacional :=& MENOR\\
		                         &       $|$ MAIOR\\
		                         &       $|$ IGUAL\\
						&$|$ DIFERENCA\\
		                              &  $|$ MENOR\_IGUAL\\
		                              &  $|$ MAIOR\_IGUAL\\\hline
		  operador\_soma :=& SOMA\\
		                           & $|$ SUB\\\hline
		  operador\_negacao :=& NEGACAO\\\hline
		  operador\_logico :=& E\_LOGICO\\
		                           &   $|$ OU\_LOGICO\\\hline
		  operador\_multiplicacao :=& MULT\\
		                                  &    $|$ DIVISAO\\\hline
		                                      	                                                          
		  fator :=& ABRE\_COL expressao FECHA\_COL\\
		                 &   $|$ var\\
		                  &  $|$ chamada\_funcao\\
		                  &  $|$ numero\\\hline
		   numero :=& INTEIRO\\
		             &         $|$ FLUTUANTE\\
		   		  &  $|$ NOTACAO\_CIENTIFICA \\\hline
		   chamada\_funcao :=& ID ABRE\_PAR lista\_argumentos FECHA\_PAR \\\hline
		    lista\_argumentos :=& lista\_argumentos VIRGULA expressao\\
		                       &        $|$ expressao\\
		                       &        $|$ vazio\\\hline
	                               				                                	                   
\end{longtable}


\section{PLY - Python Lex Yacc}

O PLY é uma ferramenta da linguagem Python para construção de compiladores populares lex e yacc. O principal objetivo do PLY é permanecer fiel ao modo como as ferramentas lex/yacc tradicionais funcionam. Isso inclui fornecer validação extensiva de entradas, relatórios de erros e diagnósticos \cite{ply}. 

Como o PLY foi desenvolvido principalmente como uma ferramenta de instrução, é possível notar a exigência em sua especificação de regras de \textit{token} e gramática. Em parte, isso acontece para detectar erros comuns de programação feitos por usuários iniciantes.

O PLY consiste em dois módulos separados; lex.py e yacc.py, ambos encontrados em um pacote do Python chamado ply. O módulo lex.py é usado para dividir o texto de entrada em uma coleção de \textit{tokens} especificados por uma coleção de regras de expressão regular. O yacc.py é usado para reconhecer a sintaxe da linguagem que foi especificada na forma de uma gramática livre de contexto \cite{ply}. 

As duas ferramentas são destinadas a trabalhar juntas. O lex.py fornece uma interface externa na forma de uma função \texttt{token()} que retorna o próximo \textit{token} válido no fluxo de entrada. Já a yacc.py chama isso repetidamente para recuperar \textit{tokens} e invocar regras gramaticais. A saída de yacc.py é geralmente uma \textit{Abstract Syntax Tree} (AST) \cite{ply}. 


\subsection{PLY para análise léxica}
Para o desenvolvimento da análise léxica, foi utilizado apenas o módulo lex.py. Para isso, o primeiro passo foi instalar o ply no ambiente linux utilizando o seguinte comando:

\texttt{pipe3 install ply}

É importante ressaltar que a versão do python deve ser acima de 3, para aceitar caracteres com acento, pois na linguagem T++ existem palavras reservadas que obrigatoriamente possuem acentos, como então e senão.


Para utilizar a ferramenta no código fonte deve-se importar o ply por meio do seguinte comando:

\texttt{\textbf{import} ply.lex \textbf{as} lex}

No código fonte da análise léxica é necessário descrever quais são as palavras reservadas e os \textit{tokens} da linguagem, como demostra na Figura~\ref{fig:Codigo1}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{./cod1}
\caption{Palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo1}
\end{figure}

Para o reconhecimento das palavras reservadas e \textit{tokens}, são definidas as expressões regulares de cada uma no código fonte por meio de regras e funções (Figura~\ref{fig:Codigo2}). As expressões regulares já foram definidas na Tabela~\ref{expressaoRegulares}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{./cod2}
\caption{Expressões regulares das palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo2}
\end{figure}

\subsection{PLY para análise sintática}
Utiliza-se o \texttt{yacc.py} para analisar a sintaxe da linguagem. Ele utiliza uma técnica conhecida como analisador LR ou\textit{ shift-reduce parsing} \textit{LR}. Essa análise LR é uma técnica \textit{bottom up} que tenta reconhecer o lado direito de várias regras gramaticais. Sempre que um lado direito válido é encontrado na entrada, os símbolos de gramática são substituídos pelo símbolo de gramática no lado esquerdo \cite{ply}.

A implementação do analisador LR é responsável por deslocar símbolos da gramática para uma pilha, analisando a pilha e o próximo \textit{token} de entrada para padrões que correspondam a uma das regras gramaticais \cite{ply}. Como exemplo, considere a expressão \texttt{3 + 5 * (10 - 20)} e a gramática definida na Figura~\ref{fig:gramaticaExem}, a saída utilizando o analisador é demonstrada na Figura~\ref{fig:Exem}.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth]{./gramaticaExemplo}
	\caption{Exemplo de regras gramaticais.}
	\label{fig:gramaticaExem}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{./exemplo}
	\caption{Exemplo do analisador LR.}
	\label{fig:Exem}
\end{figure}

De acordo com a Figura~\ref{fig:Exem}, uma máquina de estado subjacente e o \textit{token} de entrada atual determinam o passo seguinte. Se o próximo \textit{token} estiver descrito em uma regra gramatical válida, ele é transferido para a pilha. Se a parte superior da pilha contiver um lado direito válido de uma regra gramatical, ela é "reduzida" e os símbolos substituídos pelo símbolo à esquerda. Se o \textit{token} de entrada não puder ser deslocado e o topo da pilha não corresponder a nenhuma regra gramatical, ocorre um erro de sintaxe. Uma análise é considerada bem-sucedida quando o analisador atinge um estado em que a pilha de símbolos esteja vazia e não exista mais \textit{tokens} de entrada.

\subsubsection{A implementação utilizando YACC}
Para o desenvolvimento da análise sintática, foi utilizado o módulo \texttt{ply.yacc} e os \textit{tokens} obtidos da análise léxica. Para isso, foi necessário realizar duas importações no código:

\texttt{\textbf{import} ply.yacc \textbf{as} yacc}

\texttt{\textbf{from} lexer \textbf{import} Lexica}

Cada regra gramatical é definida por uma função Python, no qual cada uma contém a especificação gramatical livre de contexto apropriada. As instruções que compõem o corpo da função implementam as ações responsável por adicionar valores na árvore abstrata, como mostra parte do código na Figura~\ref{fig:syntax}. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{./syntax}
	\caption{Regras gramaticais representadas por meio de funções na linguagem Python.}
	\label{fig:syntax}
\end{figure}

Cada função aceita um único argumento p que é uma sequência contendo os valores de cada símbolo gramatical na regra correspondente. Os valores de \texttt{p[i]} são mapeados para símbolos de gramática, como o exemplo \textbf{\texttt{p[0] = Tree('declaracao'), [p[1]]}}, no qual é adicionada na árvore o valor p[1], que pode ser: \texttt{declaracao\_variaveis, inicializacao\_variaveis ou declaraca\_funcao}.

A primeira regra definida na especificação \textit{yacc} determina o símbolo de gramática inicial. Sempre que a regra inicial for reduzida pelo analisador e não houver mais entrada disponível, a análise será interrompida uma árvore abstrata contendo a gramática e valores será retornada.

A estrutura da árvore abstrata é criada em uma classe denominada \texttt{Tree} (Figura~\ref{fig:tree}). Os símbolos encontrados pelo analisador sintático são adicionados nessa árvore, que é imprime todos seus nós ao final da análise por meio de uma função chamda \texttt{prinTree} (Figura~\ref{fig:printtree}). 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{./tree}
	\caption{Estrutura da classe Tree em Python.}
	\label{fig:tree}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{./printTree}
	\caption{Função responsável por imprimir a árvore abstrata em python.}
	\label{fig:printtree}
\end{figure}


Para capturar os erros de sintaxe encontrados, existe um denominada \texttt{p\_error} que retorna a linha e a coluna do código onde ocorreu o erro, como demostra a Figura~\ref{fig:error}.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{./error}
	\caption{Função error em Python.}
	\label{fig:error}
\end{figure}

Para construir o analisador, é necessário chamar a função \texttt{yacc.yacc()}, no qual examina o módulo e tenta construir todas as tabelas de análise de LR para a gramática especificada.

\section{Análise Semântica}
A análise semântica analisa possíveis erros no código da linguagem T++, percorrendo a árvore abstrata gerada pela a análise sintática. Para isso, foi necessário importar o código da análise sintática e na função inicial obter a árvore gerada por ela:

\texttt{\textbf{from} syntax \textbf{import} Syntax}

\texttt{\textbf{self}.tree = Syntax(code).ast }

%estratégias utilizadas para a analise
Para verificar a existências de erros, foi analisado cada nó filho (saída da árvore), percorrendo suas instruções até chegar em alguma instrução no código, como declaração e inicialização de variáveis ou chamadas de funções, verificando a existência de alguma inconsistência não condizente com a estrutura permitida na linguagem. À medida que essas instruções são percorridas, ao identificar variáveis ou funções, elas são adicionadas em uma tabela de símbolos, armazenando seus valores que auxiliam a definir se a ação é ou não permitida no código.

A tabela de símbolos é um dicionário de dados responsável por armazenar todas as variáveis e funções presente no código e seus atributos, como o escopo, nome, tipo e quantidade de parâmetros, em caso de funções. A seguir é demonstrado um exemplo da tabela de símbolo:

\texttt{\{'\textbf{principal}': ['funcao', 'principal', 'void', 'inteiro', 0],}

\texttt{'\textbf{global-a}': ['variavel', 'a', False, 'flutuante', 1],}\}

Para as funções, como a \texttt{principal}, na primeira posição do vetor é armazenado o atributo (função), na segunda o nome da função, na terceira armazena os tipos dos parâmetros (se tiver), na quarta armazena o tipo da função e a na sexta um valor 0 e 1, sendo 1 função utilizada e 0 não utilizada.

Já para as variáveis, como a \texttt{golobal-a}, significa que ela possui escopo global, e a primeira posição do vetor armazena se é variável, a segunda o seu valor (\texttt{a}), a terceira se ela foi inicializada (True sim e False não), a quinta armazena o tipo da variável e a sexta um valor de binário que identifica se a variável foi utilizada.


Inicialmente, o primeiro nó filho será "programa", dessa forma a análise semântica inicia-se na função \texttt{programa}, recebendo a árvore como parâmetro. O próximo passo é verificar seu filho, que é "lista\_declarações", chamando respectivamente a função com esse nome. A partir de então é verificado se existe declaração de variáveis, função ou inicialização de variáveis. Ao passo que identifica os nós filhos, é chamada a função que condiz com ele.

Em algumas dessas funções são realizadas a análise de erro, com o auxílio da tabela de símbolos. Para melhor compreensão, considere a função \texttt{verifica\_var} demonstrada na Figura~\ref{var}.

\begin{figure}[h]
\caption{Análise semântica: Função verifica\_var responsável por determinar erros das variáveis.}
\label{var}
\begin{lstlisting}[frame=single] 
def verifica_var(self, node):
 nome = self.escopo + "-" + node.value
 apenasNome = node.value
        
 if nome not in self.tabelaSimbolos:
  nome = "global-" + node.value
  if nome not in self.tabelaSimbolos:
   print("Erro:Váriavel'" + node.value + "'não declarada")
  else:
   if self.tabelaSimbolos[nome][2] == False:
    print("Erro: Váriavel'"+apenasNome+"'não inicializada.")  
      
 if nome in self.tabelaSimbolos:
  self.tabelaSimbolos[nome][4] = 1
  return self.tabelaSimbolos[nome][3]
 \end{lstlisting}
\end{figure}

A função \texttt{verifca\_var} é responsável por identificar e verificar se a variável (\texttt{node}) recebida por parâmetro foi declarada ou inicializada. Para isso é pesquisado na tabela de símbolos o escopo correspondente a variável, se é global ou se está em alguma função. Se a variável não estiver na tabela, é mostrado uma mensagem de erro informando que essa não foi declarada. Se ela estiver, é realizado uma nova verificação, na qual analisa se a posição 2 na tabela de símbolos é False, se sim, outra mensagem é informada dizendo que a variável é utilizada, porém não foi inicializada. Por fim, se a variável estiver na tabela, é atribuído um novo valor na posição 4, que irá identificar que essa variável está sendo utilizada no programa.

Todas as verificações seguem essa mesma ideia, verificar os atributos do nó filho na tabela de símbolos, analisa-los e retornar uma mensagem de erro, caso necessário.  Apenas três funções são chamadas ao terminar de percorrer a árvore, passando apenas a tabela de símbolos, são elas \texttt{verifica\_main}, \texttt{verifica\_variaveis} e \texttt{verifica\_funcoes}, cujo objetivo é, respectivamente, verificar se a função principal foi declarada, se as variáveis e as funções são utilizadas.

Além de realizar as verificações, durante o percurso dos nós, é criado uma nova árvore abstrata resumida, com o objetivo de adicionar apenas as variáveis, funções e expressões no código. Para isso, foi utilizado a biblioteca Graphviz do Python.

\section{Geração de código intermediário LLVM}
Na etapa da geração de código, a árvore sintática abstrata é percorrida novamente, com o objetivo de gerar um código intermediário (RI) utilizando o LLVM-IR da linguagem Python. Como auxílio, utiliza-se a tabela de símbolos obtidas na análise e a própria árvore obtida da análise semântica.

No código da geração, foi necessário importar as bibliotecas LLVMLite, a semântica e o subprocesso \textit{call} (para a compilação do código), por meio dos seguintes comandos:


\texttt{\textbf{from} llvmlite \textbf{import} ir}

\texttt{\textbf{from} semantica \textbf{import} *}

\texttt{\textbf{from} subprocess \textbf{import} call}

Além das importações, foi necessário obter a árvore abstrata da semântica, a tabela de símbolos e criar o módulo llvm responsável pela geração por meio do \texttt{ir.Module()}. A Figura~\ref{fig:import} demonstra essas importações e a chamada de outras funções auxiliares, como a \texttt{define\_variaveis\_auxiliares()} e \texttt{salva\_arquivo}, com o objetivo de salvar e compilar a saída do código.


\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{./importacoes}
	\caption{Algumas chamadas de funções do código de geração.}
	\label{fig:import}
\end{figure}

A geração tem início na função \texttt{geracao\_codigo}, que é responsável por receber a árvore da semântica e analisar os nós filhos, chamando funções que criam ações de acordo com os nós. Por exemplo, para gerar um código de declaração de variável: a \texttt{geracao\_codigo} chama \texttt{lista\_declaracoes} passando o próximo nó da árvore, que chama \texttt{declaracao}, no qual verifica se recebeu algum nó de declaração de variáveis, para então chamar a função \texttt{declaracao\_variaveis}, responsável pela geração de código.

As estratégias utilizadas para a geração seguiram o padrão do LLVM. Algumas delas são, inicializar variáveis globais e locais utilizando o \texttt{ir.IntType(32)} ou  \texttt{ir.FloatTpe()}; Carregar uma variável e dar store nela por meio do \texttt{builder.load(variável, nome)}, \texttt{builder.store(variavel, nome)}, respectivamente; Chamar um procedimento com \texttt{builder.call(função, valores)}; entre outras.


Para executar o código intermediário gerado, é preciso: ter instalado LLVM com versão superior a 3.4, ou possuir o executável do LLC; e ter a biblioteca \texttt{print\_scanf.o}. No próprio código, existe uma função responsável por realizar todas as execuções e mostrar no terminal a saída. Essa função é \texttt{salva\_arquivo} e parte dela está descrita na Figura~\ref{fig:salva}.


\begin{figure}[h]
\caption{Fatorial em T++.}
\label{fig:salva}
\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{lstlisting}[frame=single] 
(...)
call("./llc gera.ll --mtriple \"x86_64-unknown-linux-gnu\"", 
											shell=True)
call("gcc -c gera.s", shell=True)
call("gcc -o saidaGeracao gera.o print_scanf.o", 
										shell=True)
call("./saidaGeracao", shell=True)
\end{lstlisting}
\end{figure}

Se desejar executar sem ser pelo executável, na primeira chamada \texttt{call} deve ser excluído o \texttt{./}.

\section{Os resultados}
\subsection{Resultados da análise léxica}
Com o código fonte da análise léxica pronto, é possível executá-lo de forma que receba um arquivo contendo o código na linguagem T++, leia cada \textit{token} do mesmo, e retorne um arquivo de saída identificando cada \textit{token} encontrado, bem como sua linha e coluna.

Para executar o código pelo terminal utiliza-se o seguinte comando:

\texttt{python3 lexer.py nomeDoArquivo.tpp}

Considere a Figura~\ref{fig:fat} que demostra um código feito em T++ responsável por calcular o fatorial de um número. 

\begin{figure}[h]
\caption{Fatorial em T++.}
\label{fig:fat}
\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{lstlisting}[frame=single] 
inteiro: n
inteiro fatorial(inteiro: n)
    inteiro: fat
    se n > 0 então {não calcula se n > 0}
        fat := 1
        repita
            fat := fat * n
            n := n - 1
        até n = 0
        retorna(fat) {retorna o valor do fatorial de n}
    senão
        retorna(0)
    fim
fim
inteiro principal()
    leia(n)
    escreva(fatorial(n))
    retorna(0)
fim

\end{lstlisting}
\end{figure}

Ao executar a análise léxica o código fatorial (Figura~\ref{fig:fat}), tem-se a seguinte saída:

\begin{lstlisting}[frame=single] 
LexToken(INTEIRO,'inteiro',1,0)
LexToken(DOIS_PONTOS,':',1,7)
LexToken(ID,'n',1,9)
LexToken(NOVA_LINHA,'\n\n',1,10)
LexToken(INTEIRO,'inteiro',3,12)
LexToken(ID,'fatorial',3,20)
LexToken(ABRE_PAR,'(',3,28)
LexToken(INTEIRO,'inteiro',3,29)
LexToken(DOIS_PONTOS,':',3,36)
LexToken(ID,'n',3,38)
LexToken(FECHA_PAR,')',3,39)
LexToken(NOVA_LINHA,'\n',3,40)
LexToken(INTEIRO,'inteiro',4,45)
LexToken(DOIS_PONTOS,':',4,52)
LexToken(ID,'fat',4,54)
LexToken(NOVA_LINHA,'\n',4,57)
LexToken(SE,'se',5,62)
LexToken(ID,'n',5,65)
LexToken(MAIOR,'>',5,67)
LexToken(INTEIRO,'0',5,69)
LexToken(ENTAO,'então',5,71)
LexToken(COMENTARIO,'{não calcula se n > 0}',5,77)
LexToken(NOVA_LINHA,'\n',5,99)
LexToken(ID,'fat',6,108)
LexToken(ATRIBUICAO,':=',6,112)
LexToken(INTEIRO,'1',6,115)
LexToken(NOVA_LINHA,'\n',6,116)
LexToken(REPITA,'repita',7,125)
LexToken(NOVA_LINHA,'\n',7,131)
LexToken(ID,'fat',8,144)
LexToken(ATRIBUICAO,':=',8,148)
LexToken(ID,'fat',8,151)
LexToken(MULT,'*',8,155)
LexToken(ID,'n',8,157)
LexToken(NOVA_LINHA,'\n',8,158)
LexToken(ID,'n',9,171)
LexToken(ATRIBUICAO,':=',9,173)
LexToken(ID,'n',9,176)
LexToken(SUB,'-',9,178)
LexToken(INTEIRO,'1',9,180)
LexToken(NOVA_LINHA,'\n',9,181)
LexToken(ATE,'até',10,190)
LexToken(ID,'n',10,194)
LexToken(IGUAL,'=',10,196)
LexToken(INTEIRO,'0',10,198)
LexToken(NOVA_LINHA,'\n',10,199)
LexToken(RETORNA,'retorna',11,208)
LexToken(ABRE_PAR,'(',11,215)
LexToken(ID,'fat',11,216)
LexToken(FECHA_PAR,')',11,219)
LexToken(COMENTARIO,'{retorna ...}',11,221)
LexToken(NOVA_LINHA,'\n',11,255)
LexToken(SENAO,'senão',12,260)
LexToken(NOVA_LINHA,'\n',12,265)
LexToken(RETORNA,'retorna',13,274)
LexToken(ABRE_PAR,'(',13,281)
LexToken(INTEIRO,'0',13,282)
LexToken(FECHA_PAR,')',13,283)
LexToken(NOVA_LINHA,'\n',13,284)
LexToken(FIM,'fim',14,289)
\end{lstlisting}

É possível notar que o código da análise léxica avaliou cada palavra do código em T++, o classificou e retornou seu valor em um arquivo de saída. Isso é exatamente o objetivo da análise léxica, retornar todos os \textit{tokens} que um determinado código possui.


\subsection{Resultados da análise sintática}
O código da análise sintática recebe um arquivo contendo o código na linguagem T++. Ele chama a análise léxica para obter os \textit{tokens} e analisar se esses correspondem a gramática descrita.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.45\linewidth]{./codigo}
	\caption{Código em T++.}
	\label{fig:codigo}
\end{figure}

Considere o código fatorial da Figura~\ref{fig:codigo}, a saída obtida quando executado a análise sintática desse código é uma árvore abstrata que está representada na Figura~\ref{fig:asa}.

\subsection{Resultados da análise semântica}
O código da análise semântica recebe um arquivo contendo o programa na linguagem T++. Ele chama a análise sintática para obter a árvore abstrata gerada, analisando a estrutura e verificando se existem erros no programa. Como saída, tem-se a tabela de símbolos, possíveis mensagens de erros e uma árvore sintática abstrata anotada.

Como exemplo de saída, considere o código descrito na linguagem T++, especificado na Figura~\ref{codSemantica}.

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)
\begin{figure}[h]
\caption{Exemplo de código na linguagem T++.}
\label{codSemantica}
\begin{lstlisting}[frame=single] 
flutuante: a
inteiro: b

func()
  a := 10.2
  retorna(a)
fim

inteiro principal()
	b := 5
	func()
fim
\end{lstlisting}
\end{figure}

A saída obtida ao executar a análise semântica retorna um erro e um aviso. O primeiro indica que a função \texttt{func} deveria retornar vazio, mas retorna uma variável do tipo flutuante. Já o segundo é que a função \texttt{principal} deveria retornar inteiro, mas não retorna nenhum valor. A Figura~\ref{fig:erroSaida} mostra essa saída obtida pelo terminal.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{./erro}
	\caption{Saída da análise semântica: erros.}
	\label{fig:erroSaida}
\end{figure}

Além das mensagens de erros, também foi obtido como saída a tabela de símbolos correspondente ao código. A variável \texttt{b} foi armazenada como escopo global, tendo como características, tipo inteiro, sendo inicializada e utilizada. A variável global \texttt{a} também é inicializada e utilizada, porém possui tipo flutuante. Já a função \texttt{func}, não possui tipo nem listas de parâmetros e é utilizada. Por fim, a função \texttt{principal} é do tipo inteiro e também não possui parâmetros de entrada. A Figura~ apresenta os valores da tabela de símbolos obtidos.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{./ts}
	\caption{Saída da análise semântica: tabela de símbolos.}
	\label{fig:ts}
\end{figure}

Por fim, é gerada e salvo em formato SVG uma árvore abstrata resumida da análise sintática (Figura~\ref{fig:asto}).


\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{./asto}
	\caption{Saída da análise semântica: árvore sintática abstrata anotada.}
	\label{fig:asto}
\end{figure}


\subsection{Resultados da geração de código}
O código da geração de código recebe um arquivo contendo o programa na linguagem T++. Ele cama a análise semântica para obter as mensagens e a árvore gerada. Como saída, é obtido um código IR gerado em LLVM e possíveis mensagens de erros da linguagem.

Como exemplo de saída, considere um código simples descrito na linguagem T++, que deve mostrar como saída o valor da variável \texttt{ret}(Figura~\ref{fig:exemploGen}).

A saída obtida ao executar a geração o módulo LLVM contendo todas as instruções necessárias para executar o programa e o resultado da variável \texttt{ret} que é o valor 1. A Figura~\ref{fig:saidaGen} mostra a saída obtida no terminal.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.45\linewidth]{./exemploGen}
	\caption{Exemplo de código na linguagem T++.}
	\label{fig:exemploGen}
\end{figure}



\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{./saidaGen}
	\caption{Saída da geração de código: Resultados obtidos pelo terminal.}
	\label{fig:saidaGen}
\end{figure}

\bibliographystyle{sbc}
\bibliography{sbc-template}
\nocite{expRegular}


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{./asa}
	\caption{Resultado análise sintática: árvore sintática abstrata.}
	\label{fig:asa}
\end{figure}
\end{document}
