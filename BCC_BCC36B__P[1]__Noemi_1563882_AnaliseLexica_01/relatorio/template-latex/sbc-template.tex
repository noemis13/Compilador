\documentclass[12p, english,brazil,a4paper,utf8,onesidet]{article}
\usepackage{float}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[latin1]{inputenc}  
\usepackage{url}
\usepackage{indentfirst}
\usepackage[brazil]{babel} 
\usepackage{tabularx}
\usepackage{hhline}
\usepackage{xcolor}
\usepackage{nomencl}
\usepackage{indentfirst}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{etoolbox}
\usepackage{listings}
\usepackage{cleveref}
     
% Suporte a figuras e subfiguras
\usepackage{graphics}
\usepackage{subfigure}
     
\sloppy

\title{Análise Léxica}

\author{Noemi Pereira Scherer\inst{1}}


\address{Universidade Tecnológica Federal do Paraná (UTFPR)
  \\
  Campo Mourão -- PR -- Brasil
  \email{\{noemischerer13\}@gmail.com}
}

\begin{document} 

\maketitle

\begin{abstract}
  This meta-article describes the procedures and results of the development of a lexical analyzer, which is responsible for verifying the input of character lines from a T ++ written source code, producing a synonym of lexical symbols. For the creation of this analyze, a Python language library called PLY was used.	
\end{abstract}
     
\begin{resumo} 
  Este meta-artigo descreve os procedimentos e resultados do desenvolvimento de um analisador léxico, que é responsável por verificar as entradas de linhas de caracteres de um código fonte escrito T++, produzindo uma senquência de símbolos léxicos. Para a criação desse analisar, foi utilizado uma biblioteca da linguagem Python denominado PLY.
  
\end{resumo}


\section{Introdução}
A análise léxica é um processo que analisa a entrada de linhas de caracteres (código fonte de um programa) e produz uma sequência de símbolos léxicos denominados \textit{tokens}, sendo facilmente manipulado por um \textit{parser} (leitor de saída) \cite{wikibook}.

O analisador léxico lê cada caractere do programa fonte e, traduz em uma saída os \textit{tokens}. Dessa forma, é possível reconhecer as palavras reservadas, constantes, identificadores e outras palavras que pertencem a linguagem de programação analisada. O analisador também pode executar outras tarefas como o tratamento de espaços, eliminação de comentários e contagem do número de linhas que o programa possui \cite{wikibook}.

O analisador léxico funciona de duas maneiras o primeiro e segundo estado da análise. O primeiro é responsável por ler a entrada de caracteres mudando o estado em que esses se encontram. Quando o analisador encontra um caractere o qual ele não considera como correto, ele volta à última análise que foi aceita. No segundo são repassados os caracteres encontrados para produzir um valor. O tipo do léxico é combinado com seu valor constituindo um símbolo, que pode ser denominado parser.

A implementação de um analisador léxico requer uma descrição do autômato que reconhece as sentenças da gramática ou expressão regular de cada \textit{token} que possui os seguintes procedimentos \cite{wikibook}:
\begin{itemize}
\item Estado inicial, que recebe como argumento a referência para o autômato e retorna o seu estado inicial;

\item Estado final, que recebe como argumentos a referência para o autômato e a referência para o estado corrente. O procedimento retorna verdadeiro se o estado especificado é elemento do conjunto de estados finais do autômato, ou falso caso contrário; e

\item Próximo estado, que recebe como argumento a referência para o autômato, para o estado corrente e para o símbolo sendo analisado. O procedimento consulta a tabela de transições e retorna o próximo estado do autômato, ou o valor nulo se não houver transição possível.
\end{itemize}


\subsection{Objetivo}
O objetivo desse trabalho é desenvolver em um programa capaz de realizar a análise léxica de códigos fontes escrito na Linguagem T++, retornando o conjunto de \textit{tokens} encontrado.

\section{A Linguagem T++} \label{sec:firstpage}
A linguagem T++ foi desenvolvida especialmente para ser utilizada na disciplina de compiladores. Ela é uma linguagem simples, contendo algumas palavras reservadas, símbolos e arranjos uni e bidimensionais. A Tabela \ref{linguagemt} mostra todas as palavras reservadas e símbolos que a linguagem T++ permite.


\begin{table}[H]
\caption{\textit{Tokens} permitidos pela Linguagem T++}
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Palavras Reservadas}& \textbf{Símbolos}\\ 
\hline
se    & + soma\\\hline
então & - subtração\\\hline
senão & * multiplicação\\\hline
fim	  & / divisão\\\hline
repita& = igualdade\\\hline
flutuante& , vírgula\\\hline
retorna& := atribuição\\\hline
até& $<$ menor\\\hline
leia& $>$ maior\\\hline
escreve& $<$= menor-igual\\\hline
inteiro& $>$= maior-igual\\\hline
notação científica	& () abre e fecha parênteses\\\hline
		& : dois pontos\\\hline
		& [] abre e fecha colchetes\\\hline
		& \{\} comentário\\\hline
		& $|$ $|$ ou-lógico \\\hline
		& \&\& e-lógico \\\hline
		& ! negação \\\hline	
		
\end{tabular}
\label{linguagemt}
\end{table}

 
A construção do código dessa linguagem é inteiramente em Português. Os números podem ser inteiros, flutuantes (notação científica ou não), e as declarações de variáveis devem obrigatoriamente começar com letras precedente de várias letras e/ou números.
 
Apesar de T++ ser uma linguagem simples, ela permite a execução de algoritmos complexos, como de ordenação. A Figura~\ref{exemple} demonstra o algoritmo de busca BubbleSort na linguagem t++.

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)

\begin{figure}[H]
\caption{Exeplo do código BubbleSort na linguagem T++}
\label{exemple}
\begin{lstlisting}[frame=single] 
inteiro: vet[10]
inteiro: tam
tam := 10

preencheVetor()
  inteiro: i
  inteiro: j
  i := 0
  j := tam
  repita
    vet[i] = j
    i := i + 1
    j := j - 1
  até i < tam
fim

bubble_sort()
  inteiro: i
  i := 0
  repita
    inteiro: j
    j := 0
    repita
      se vet[i] > v[j] então
        inteiro: temp
        temp := vet[i]
        vet[i] := vet[j]
        vet[j] := temp
      fim
      j := j + 1
    até j < i
    i := i + 1
  até i < tam
fim

inteiro principal()
  preencheVetor()
  bubble_sort()
  retorna(0)
fim
\end{lstlisting}
\end{figure}

\section{Expressões Regulares e Autômatos}

Uma expressão regular é responsável por identificar cadeia de caracteres de uma determinada linguagem, como palavras ou padrões. Elas são escritas numa linguagem formal que pode ser interpretada por um processador de expressão regular \cite{expRegular}.

Essa expressão pode ser associada com a aritmética, entretanto ao invés dela denotar um número (como 2+2), a expressão regular denota uma linguagem regular. Por exemplo: a0+, que resultará em \{"a0", "a00", "a000", ...\} \cite{expRegular}.

As expressões regulares são utilizadas para a especificação léxica de uma determinada linguagem. Para sua demonstração são utilizados autômatos finitos determinísticos.

Um autômato finito é um modelo computacional composto de uma fita de entrada dividida em células, nas quais contém os símbolos das cadeia. A principal parte do modelo é um controle finito, o qual indica em qual estado o autômato se encontra \cite{automatos}.

O modelo do autômato apresenta um estado inicial e um conjunto de estados finais. O estado inicial refere-se ao início de funcionamento do modelo, dependendo do símbolo presente na fita o próximo estado será escolhido, enquanto que os estados finais indicam o término do processo com sucesso, ou seja, se a cadeia presente na fita de entrada tiver sido completamente lida e o modelo não se encontrar em um estado final, considera-se a cadeia não aceita, ou caso contrário, como aceita \cite{automatos}.

% % %
Para cada \textit{token} permitido na Linguagem T++ é criado uma expressão regular, o qual tem como objetivo analisar uma cadeia de caracteres no código. As expressões regulares utilizadas nesse trabalho estão descritas na Tabela~\ref{expressaoRegulares}.

\begin{table}[H]
\caption{Expressões regulares de cada token}
\centering
\begin{tabular}{|l|c|}
\hline
\textbf{Tokens} & \textbf{Expressão regulares}\\ 
\hline

Soma & \textbackslash+ \\\hline
Subtração & - \\\hline
Multiplicação & \textbackslash* \\\hline
Divisão & \textbackslash/ \\\hline
Igual & \textbackslash = \\\hline
Vírgula & , \\\hline
Atribuição & \textbackslash:=+ \\\hline
Menor & \textbackslash< \\\hline
Maior & \textbackslash> \\\hline
Menor Igual & \textbackslash<= \\\hline
Maior igual & \textbackslash>= \\\hline
Abre parênteses & \textbackslash $($ \\\hline
Fecha parênteses & \textbackslash $)$ \\\hline
Abre colchetes & \textbackslash $[$ \\\hline
Fecha Colchetes & \textbackslash $]$ \\\hline
Dois pontos & : \\\hline
E lógico & \&\& \\\hline
OU lógico & $|$ $|$ \\\hline
Negação & ! \\\hline

ID & [a-zA-Zà-úÀ-Ú][\_0-9a-zà-úA-ZÀ-Ú]* \\\hline

Notação Científica & [0-9]+(\textbackslash .[0-9]+)*(e$|$ 
E)+(\textbackslash + $|$\textbackslash -)*[0-9]+(\textbackslash.[0-9])* \\\hline		

Flutuante & [0-9]+(\textbackslash.[0-9]+)(e( \textbackslash +$|$ \textbackslash-)?(\ d+))? \\\hline

Inteiro & [0-9]+ \\\hline

Comentário & \{ [ 
\textasciicircum \textbackslash \{ 
\textasciicircum \textbackslash \} ] \} \\\hline

Nova Linha & \textbackslash n+ \\\hline

\end{tabular}
\label{expressaoRegulares}
\end{table}

A ordem de execução de cada expressão regular é representada em forma de autômatos. Os autômatos mais simples são dos operadores (soma, subtração, divisão, multiplicação, abre e fecha parênteses e colchetes, atribuição, igualdade, vírgula, dois pontos, ou e e-lógico e negação) que são representados na Figura~\ref{fig:ExpressaoOperadores}.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./palavrasReservadas}
\caption{Autômatos dos operadores.}
\label{fig:ExpressaoOperadores}
\end{figure}

Os autômatos da expressão regular do ID (identificador) estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoId1}), e outro detalhada (Figura~\ref{fig:ExpressaoId2}). O seu objetivo é identificar qualquer palavra ou letra presente no código, podendo ser letras maiúsculas, minúsculas, com ou sem assento. 

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./id1}
\caption{Autômato resumido da expressão regular do identificador (ID).}
\label{fig:ExpressaoId1}
\end{figure}
 

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{./id2}
\caption{Autômato completo da expressão regular do identificador (ID).}
\label{fig:ExpressaoId2}
\end{figure}

O autômato da expressão regular dos números inteiros recebe qualquer número de zero a nove uma ou várias vezes até chegar em seu estado final. Ele está representado na Figura~\ref{fig:ExpressaoInteiro}. 

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./inteiro1}
\caption{Autômato dos números inteiros.}
\label{fig:ExpressaoInteiro}
\end{figure}

O autômato da expressão regular dos números flutuantes está representado na Figura~\ref{fig:ExpressaoFlutuante}. Seu objetivo é identificar qualquer número que esteja separado por ponto no código, como 22.5 ou 0.22. 

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./flutuante2}
\caption{Autômato dos números flutuantes.}
\label{fig:ExpressaoFlutuante}
\end{figure}


O autômato da expressão regular dos números flutuantes em notação científica está representado na Figura~\ref{fig:ExpressaoNotacao}. Seu objetivo é identificar valor que possuem expoente no código, como 10E20 ou 10e-20. 

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./notacao}
\caption{Autômato dos números flutuantes em notação científica.}
\label{fig:ExpressaoNotacao}
\end{figure}


Os autômatos da expressão regular dos comentários estão representados de duas formas, uma resumida (Figura~\ref{fig:ExpressaoComent}) e outra detalhada (Figura~\ref{fig:ExpressaoComent2}). Os comentários no na linguagem T++ são representadas por qualquer palavra que esteja entre '\{\}', como exemplo: \{Esse é um comentário \}.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./comentario1}
\caption{Autômato resumido do comentário.}
\label{fig:ExpressaoComent}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./comentario2}
\caption{Autômato completo do comentário.}
\label{fig:ExpressaoComent2}
\end{figure}


Por fim, o autômato da expressão regular da nova linha está representado representado na Figura~\ref{fig:ExpressaoLinha}. Seu objetivo é encontrar qualquer linha no código denotado por \textbackslash n.

\begin{figure}[H]
\centering
\includegraphics[width=0.7\linewidth]{./linha1}
\caption{Autômato da nova linha.}
\label{fig:ExpressaoLinha}
\end{figure}


\section{PLY - Python Lex Yacc e o Código}

O PLY é uma ferramenta da linguagem Python para construção de compiladores populares lex e yacc. O principal objetivo do PLY é permanecer fiel ao modo como as ferramentas lex/yacc tradicionais funcionam. Isso inclui fornecer validação extensiva de entradas, relatórios de erros e diagnósticos \cite{ply}. 

Como o PLY foi desenvolvido principalmente como uma ferramenta de instrução, é possível notar a exigência em sua especificação de regras de \textit{token} e gramática. Em parte, isso acontece para detectar erros comuns de programação feitos por usuários iniciantes.

O PLY consiste em dois módulos separados; lex.py e yacc.py, ambos encontrados em um pacote do Python chamado ply. O módulo lex.py é usado para dividir o texto de entrada em uma coleção de \textit{tokens} especificados por uma coleção de regras de expressão regular. O yacc.py é usado para reconhecer a sintaxe da linguagem que foi especificada na forma de uma gramática livre de contexto \cite{ply}. 

As duas ferramentas são destinadas a trabalhar juntas. O lex.py fornece uma interface externa na forma de uma função \texttt{token()} que retorna o próximo \textit{token} válido no fluxo de entrada. Já a yacc.py chama isso repetidamente para recuperar \textit{tokens} e invocar regras gramaticais. A saída de yacc.py é geralmente uma \textit{Abstract Syntax Tree} (AST) \cite{ply}. 

Para o desenvolvimento da análise sintática, foi utilizado apenas o módulo lex.py. Para isso, o primeiro passo foi instalar o ply no ambiente linux utilizando o seguinte comando:

\texttt{pipe3 install ply}

É importante ressaltar que a versão do python deve ser acima de 3, para aceitar caracteres com acento, pois na linguagem T++ existem palavras reservadas que obrigatoriamente possuem acentos, como então e senão.

Para utilizar a ferramenta no código fonte deve-se importar o ply por meio do seguinte comando:

\texttt{\textbf{import} ply.lex \textbf{as} lex}


No código fonte da análise léxica é necessário descrever quais são as palavras reservadas e os \textit{tokens} da linguagem, como demostra na Figura~\ref{fig:Codigo1}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{./cod1}
\caption{Palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo1}
\end{figure}

Para o reconhecimento das palavras reservadas e \textit{tokens}, são definidas as expressões regulares de cada uma no código fonte por meio de regras e funções (Figura~\ref{fig:Codigo2}). As expressões regulares já foram definidas na Tabela~\ref{expressaoRegulares}.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{./cod2}
\caption{Expressões regulares das palavras reservadas e \textit{tokens} no código fonte da análise léxica.}
\label{fig:Codigo2}
\end{figure}

\section{Resultados}

Com o código fonte da análise léxica pronta, é possível executá-lo de forma que receba um arquivo contendo o código na linguagem T++, leia cada \textit{token} do mesmo, e retorne um arquivo de saída identificando cada \textit{token} encontrado, bem como sua linha e coluna.

Para executar o código pelo terminal utiliza-se o seguinte comando:

\texttt{python3 lexer.py nomeDoArquivo.tpp}

Considere o seguinte código feito em T++ responsável por calcular o fatorial de um número:

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)

\begin{lstlisting}[frame=single] 
inteiro: n
inteiro fatorial(inteiro: n)
    inteiro: fat
    se n > 0 então {não calcula se n > 0}
        fat := 1
        repita
            fat := fat * n
            n := n - 1
        até n = 0
        retorna(fat) {retorna o valor do fatorial de n}
    senão
        retorna(0)
    fim
fim
inteiro principal()
    leia(n)
    escreva(fatorial(n))
    retorna(0)
fim

\end{lstlisting}

Quando executado o código da análise léxica para o exemplo anterior, tem-se a seguinte saída:

\lstset{language=c}          % Set your language (you can change the language for each code-block optionally)

\begin{lstlisting}[frame=single] 
LexToken(INTEIRO,'inteiro',1,0)
LexToken(DOIS_PONTOS,':',1,7)
LexToken(ID,'n',1,9)
LexToken(NOVA_LINHA,'\n\n',1,10)
LexToken(INTEIRO,'inteiro',3,12)
LexToken(ID,'fatorial',3,20)
LexToken(ABRE_PAR,'(',3,28)
LexToken(INTEIRO,'inteiro',3,29)
LexToken(DOIS_PONTOS,':',3,36)
LexToken(ID,'n',3,38)
LexToken(FECHA_PAR,')',3,39)
LexToken(NOVA_LINHA,'\n',3,40)
LexToken(INTEIRO,'inteiro',4,45)
LexToken(DOIS_PONTOS,':',4,52)
LexToken(ID,'fat',4,54)
LexToken(NOVA_LINHA,'\n',4,57)
LexToken(SE,'se',5,62)
LexToken(ID,'n',5,65)
LexToken(MAIOR,'>',5,67)
LexToken(INTEIRO,'0',5,69)
LexToken(ENTAO,'então',5,71)
LexToken(COMENTARIO,'{não calcula se n > 0}',5,77)
LexToken(NOVA_LINHA,'\n',5,99)
LexToken(ID,'fat',6,108)
LexToken(ATRIBUICAO,':=',6,112)
LexToken(INTEIRO,'1',6,115)
LexToken(NOVA_LINHA,'\n',6,116)
LexToken(REPITA,'repita',7,125)
LexToken(NOVA_LINHA,'\n',7,131)
LexToken(ID,'fat',8,144)
LexToken(ATRIBUICAO,':=',8,148)
LexToken(ID,'fat',8,151)
LexToken(MULT,'*',8,155)
LexToken(ID,'n',8,157)
LexToken(NOVA_LINHA,'\n',8,158)
LexToken(ID,'n',9,171)
LexToken(ATRIBUICAO,':=',9,173)
LexToken(ID,'n',9,176)
LexToken(SUB,'-',9,178)
LexToken(INTEIRO,'1',9,180)
LexToken(NOVA_LINHA,'\n',9,181)
LexToken(ATE,'até',10,190)
LexToken(ID,'n',10,194)
LexToken(IGUAL,'=',10,196)
LexToken(INTEIRO,'0',10,198)
LexToken(NOVA_LINHA,'\n',10,199)
LexToken(RETORNA,'retorna',11,208)
LexToken(ABRE_PAR,'(',11,215)
LexToken(ID,'fat',11,216)
LexToken(FECHA_PAR,')',11,219)
LexToken(COMENTARIO,'{retorna ...}',11,221)
LexToken(NOVA_LINHA,'\n',11,255)
LexToken(SENAO,'senão',12,260)
LexToken(NOVA_LINHA,'\n',12,265)
LexToken(RETORNA,'retorna',13,274)
LexToken(ABRE_PAR,'(',13,281)
LexToken(INTEIRO,'0',13,282)
LexToken(FECHA_PAR,')',13,283)
LexToken(NOVA_LINHA,'\n',13,284)
LexToken(FIM,'fim',14,289)

\end{lstlisting}

É possível notar que o código da análise léxica avaliou cada palavra do código em T++, o classificou e retornou seu valor em um arquivo de saída. Isso é exatamente o objetivo da análise léxica, retornar todos os \textit{tokens} que um determinado código possui.

\bibliographystyle{sbc}
\bibliography{sbc-template}
\nocite{expRegular}
\end{document}
